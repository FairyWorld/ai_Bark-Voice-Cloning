{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOCJ+WW9x8MwttlUSfkYUdm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KevinWang676/Bark-Voice-Cloning/blob/main/GPT_SoVITS_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yf_VVPlApT8H",
        "outputId": "dffce40b-b9b9-4d08-a411-c4f9aa127c84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏬ Downloading https://repo.anaconda.com/miniconda/Miniconda3-py39_23.11.0-2-Linux-x86_64.sh...\n",
            "📦 Installing...\n",
            "📌 Adjusting configuration...\n",
            "🩹 Patching environment...\n",
            "⏲ Done in 0:00:26\n",
            "🔁 Restarting kernel...\n",
            "Cloning into 'GPT-SoVITS-v3'...\n",
            "remote: Enumerating objects: 421, done.\u001b[K\n",
            "remote: Counting objects: 100% (418/418), done.\u001b[K\n",
            "remote: Compressing objects: 100% (394/394), done.\u001b[K\n",
            "remote: Total 421 (delta 67), reused 0 (delta 0), pack-reused 3 (from 1)\u001b[K\n",
            "Receiving objects: 100% (421/421), 6.07 MiB | 5.14 MiB/s, done.\n",
            "Resolving deltas: 100% (67/67), done.\n",
            "Filtering content: 100% (23/23), 4.45 GiB | 59.22 MiB/s, done.\n",
            "Channels:\n",
            " - pytorch\n",
            " - nvidia\n",
            " - defaults\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - cudatoolkit\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    archspec-0.2.3             |     pyhd3eb1b0_0          47 KB\n",
            "    ca-certificates-2024.12.31 |       h06a4308_0         128 KB\n",
            "    certifi-2025.1.31          |   py39h06a4308_0         162 KB\n",
            "    conda-24.11.3              |   py39h06a4308_0         921 KB\n",
            "    cudatoolkit-11.7.0         |      hd8887f6_10       831.6 MB  nvidia\n",
            "    frozendict-2.4.2           |   py39h5eee18b_0          55 KB\n",
            "    openssl-3.0.15             |       h5eee18b_0         5.2 MB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:       838.1 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  cudatoolkit        nvidia/linux-64::cudatoolkit-11.7.0-hd8887f6_10 \n",
            "  frozendict         pkgs/main/linux-64::frozendict-2.4.2-py39h5eee18b_0 \n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  archspec                               0.2.1-pyhd3eb1b0_0 --> 0.2.3-pyhd3eb1b0_0 \n",
            "  ca-certificates                     2023.12.12-h06a4308_0 --> 2024.12.31-h06a4308_0 \n",
            "  certifi                         2023.11.17-py39h06a4308_0 --> 2025.1.31-py39h06a4308_0 \n",
            "  conda                              23.11.0-py39h06a4308_0 --> 24.11.3-py39h06a4308_0 \n",
            "  openssl                                 3.0.12-h7f8727e_0 --> 3.0.15-h5eee18b_0 \n",
            "\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... By downloading and using the CUDA Toolkit conda packages, you accept the terms and conditions of the CUDA End User License Agreement (EULA): https://docs.nvidia.com/cuda/eula/index.html\n",
            "\n",
            "done\n",
            "/content/GPT-SoVITS-v3\n",
            "/usr/local/lib/python3.9/site-packages/conda/base/context.py:201: FutureWarning: Adding 'defaults' to channel list implicitly is deprecated and will be removed in 25.3. \n",
            "\n",
            "To remove this warning, please choose a default channel explicitly with conda's regular configuration system, e.g. by adding 'defaults' to the list of channels:\n",
            "\n",
            "  conda config --add channels defaults\n",
            "\n",
            "For more information see https://docs.conda.io/projects/conda/en/stable/user-guide/configuration/use-condarc.html\n",
            "\n",
            "  deprecated.topic(\n",
            "/usr/local/lib/python3.9/site-packages/conda/base/context.py:201: FutureWarning: Adding 'defaults' to channel list implicitly is deprecated and will be removed in 25.3. \n",
            "\n",
            "To remove this warning, please choose a default channel explicitly with conda's regular configuration system, e.g. by adding 'defaults' to the list of channels:\n",
            "\n",
            "  conda config --add channels defaults\n",
            "\n",
            "For more information see https://docs.conda.io/projects/conda/en/stable/user-guide/configuration/use-condarc.html\n",
            "\n",
            "  deprecated.topic(\n",
            "Channels:\n",
            " - conda-forge\n",
            " - pytorch\n",
            " - nvidia\n",
            " - defaults\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - cmake\n",
            "    - ffmpeg\n",
            "    - gcc\n",
            "    - gxx\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    _libgcc_mutex-0.1          |      conda_forge           3 KB  conda-forge\n",
            "    _openmp_mutex-4.5          |            2_gnu          23 KB  conda-forge\n",
            "    aom-3.9.1                  |       hac33072_0         2.6 MB  conda-forge\n",
            "    binutils_impl_linux-64-2.43|       h4bf12b8_2         5.4 MB  conda-forge\n",
            "    ca-certificates-2025.1.31  |       hbcca054_0         154 KB  conda-forge\n",
            "    cairo-1.18.0               |       h3faef2a_0         959 KB  conda-forge\n",
            "    certifi-2025.1.31          |     pyhd8ed1ab_0         159 KB  conda-forge\n",
            "    cmake-3.29.4               |       h91dbaaa_0        18.1 MB  conda-forge\n",
            "    dav1d-1.2.1                |       hd590300_0         742 KB  conda-forge\n",
            "    expat-2.6.4                |       h5888daf_0         135 KB  conda-forge\n",
            "    ffmpeg-7.0.1               | gpl_hb399a10_100         9.6 MB  conda-forge\n",
            "    font-ttf-dejavu-sans-mono-2.37|       hab24e00_0         388 KB  conda-forge\n",
            "    font-ttf-inconsolata-3.000 |       h77eed37_0          94 KB  conda-forge\n",
            "    font-ttf-source-code-pro-2.038|       h77eed37_0         684 KB  conda-forge\n",
            "    font-ttf-ubuntu-0.83       |       h77eed37_3         1.5 MB  conda-forge\n",
            "    fontconfig-2.14.2          |       h14ed4e7_0         266 KB  conda-forge\n",
            "    fonts-conda-ecosystem-1    |                0           4 KB  conda-forge\n",
            "    fonts-conda-forge-1        |                0           4 KB  conda-forge\n",
            "    freetype-2.12.1            |       h267a509_2         620 KB  conda-forge\n",
            "    fribidi-1.0.10             |       h36c2ea0_0         112 KB  conda-forge\n",
            "    gcc-14.2.0                 |       h96c4ede_1          54 KB  conda-forge\n",
            "    gcc_impl_linux-64-14.2.0   |       h6b349bd_1        69.1 MB  conda-forge\n",
            "    gettext-0.23.1             |       h5888daf_0         473 KB  conda-forge\n",
            "    gettext-tools-0.23.1       |       h5888daf_0         2.8 MB  conda-forge\n",
            "    gmp-6.3.0                  |       hac33072_2         449 KB  conda-forge\n",
            "    gnutls-3.7.9               |       hb077bed_0         1.9 MB  conda-forge\n",
            "    graphite2-1.3.13           |    h59595ed_1003          95 KB  conda-forge\n",
            "    gxx-14.2.0                 |       h96c4ede_1          54 KB  conda-forge\n",
            "    gxx_impl_linux-64-14.2.0   |       h2c03514_1        13.7 MB  conda-forge\n",
            "    harfbuzz-8.5.0             |       hfac3d4d_0         1.5 MB  conda-forge\n",
            "    icu-73.2                   |       h59595ed_0        11.5 MB  conda-forge\n",
            "    kernel-headers_linux-64-3.10.0|      he073ed8_18         921 KB  conda-forge\n",
            "    lame-3.100                 |    h166bdaf_1003         496 KB  conda-forge\n",
            "    ld_impl_linux-64-2.43      |       h712a8e2_2         654 KB  conda-forge\n",
            "    libabseil-20240116.2       | cxx17_he02047a_1         1.2 MB  conda-forge\n",
            "    libarchive-3.7.4           |       hfca40fe_0         851 KB  conda-forge\n",
            "    libasprintf-0.23.1         |       h8e693c7_0          42 KB  conda-forge\n",
            "    libasprintf-devel-0.23.1   |       h8e693c7_0          33 KB  conda-forge\n",
            "    libass-0.17.1              |       h8fe9dca_1         124 KB  conda-forge\n",
            "    libcurl-8.12.0             |       hc9e6f67_0         468 KB\n",
            "    libdrm-2.4.124             |       hb9d3cd8_0         237 KB  conda-forge\n",
            "    libexpat-2.6.4             |       h5888daf_0          72 KB  conda-forge\n",
            "    libgcc-14.2.0              |       h77fa898_1         829 KB  conda-forge\n",
            "    libgcc-devel_linux-64-14.2.0|     h41c2201_101         2.6 MB  conda-forge\n",
            "    libgcc-ng-14.2.0           |       h69a702a_1          53 KB  conda-forge\n",
            "    libgettextpo-0.23.1        |       h5888daf_0         163 KB  conda-forge\n",
            "    libgettextpo-devel-0.23.1  |       h5888daf_0          36 KB  conda-forge\n",
            "    libglib-2.80.2             |       hf974151_0         3.7 MB  conda-forge\n",
            "    libgomp-14.2.0             |       h77fa898_1         450 KB  conda-forge\n",
            "    libhwloc-2.11.2            |default_he43201b_1000         2.3 MB  conda-forge\n",
            "    libiconv-1.17              |       hd590300_2         689 KB  conda-forge\n",
            "    libidn2-2.3.7              |       hd590300_0         124 KB  conda-forge\n",
            "    libmamba-1.5.11            |       hfe524e5_0         1.8 MB\n",
            "    libmambapy-1.5.11          |   py39haf1ee3a_0         341 KB\n",
            "    libopenvino-2024.1.0       |       h2da1b83_7         4.9 MB  conda-forge\n",
            "    libopenvino-auto-batch-plugin-2024.1.0|       hb045406_7         107 KB  conda-forge\n",
            "    libopenvino-auto-plugin-2024.1.0|       hb045406_7         224 KB  conda-forge\n",
            "    libopenvino-hetero-plugin-2024.1.0|       h5c03a75_7         187 KB  conda-forge\n",
            "    libopenvino-intel-cpu-plugin-2024.1.0|       h2da1b83_7        10.4 MB  conda-forge\n",
            "    libopenvino-intel-gpu-plugin-2024.1.0|       h2da1b83_7         8.1 MB  conda-forge\n",
            "    libopenvino-intel-npu-plugin-2024.1.0|       he02047a_7         318 KB  conda-forge\n",
            "    libopenvino-ir-frontend-2024.1.0|       h5c03a75_7         196 KB  conda-forge\n",
            "    libopenvino-onnx-frontend-2024.1.0|       h07e8aee_7         1.5 MB  conda-forge\n",
            "    libopenvino-paddle-frontend-2024.1.0|       h07e8aee_7         683 KB  conda-forge\n",
            "    libopenvino-pytorch-frontend-2024.1.0|       he02047a_7         1.1 MB  conda-forge\n",
            "    libopenvino-tensorflow-frontend-2024.1.0|       h39126c6_7         1.3 MB  conda-forge\n",
            "    libopenvino-tensorflow-lite-frontend-2024.1.0|       he02047a_7         476 KB  conda-forge\n",
            "    libopus-1.3.1              |       h7f98852_1         255 KB  conda-forge\n",
            "    libpciaccess-0.18          |       hd590300_0          28 KB  conda-forge\n",
            "    libpng-1.6.43              |       h2797004_0         281 KB  conda-forge\n",
            "    libprotobuf-4.25.3         |       h08a7969_0         2.7 MB  conda-forge\n",
            "    libsanitizer-14.2.0        |       h2a3dede_1         4.3 MB  conda-forge\n",
            "    libsolv-0.7.29             |       ha6fb4c9_0         460 KB  conda-forge\n",
            "    libssh2-1.11.1             |       h251f7ec_0         308 KB\n",
            "    libstdcxx-14.2.0           |       hc0a3c3a_1         3.7 MB  conda-forge\n",
            "    libstdcxx-devel_linux-64-14.2.0|     h41c2201_101        12.9 MB  conda-forge\n",
            "    libstdcxx-ng-14.2.0        |       h4852527_1          53 KB  conda-forge\n",
            "    libtasn1-4.20.0            |       hb9d3cd8_0         115 KB  conda-forge\n",
            "    libunistring-0.9.10        |       h7f98852_0         1.4 MB  conda-forge\n",
            "    libuuid-2.38.1             |       h0b41bf4_0          33 KB  conda-forge\n",
            "    libuv-1.50.0               |       hb9d3cd8_0         870 KB  conda-forge\n",
            "    libva-2.21.0               |       h4ab18f5_2         185 KB  conda-forge\n",
            "    libvpx-1.14.1              |       hac33072_0         999 KB  conda-forge\n",
            "    libxcb-1.15                |       h0b41bf4_0         375 KB  conda-forge\n",
            "    libxml2-2.12.7             |       hc051c1a_1         688 KB  conda-forge\n",
            "    libzlib-1.2.13             |       h4ab18f5_6          60 KB  conda-forge\n",
            "    lzo-2.10                   |    hd590300_1001         167 KB  conda-forge\n",
            "    ncurses-6.5                |       h2d0b736_3         871 KB  conda-forge\n",
            "    nettle-3.9.1               |       h7ab15ed_0         988 KB  conda-forge\n",
            "    ocl-icd-2.3.2              |       hb9d3cd8_2          93 KB  conda-forge\n",
            "    opencl-headers-2024.10.24  |       h5888daf_0          53 KB  conda-forge\n",
            "    openh264-2.4.1             |       h59595ed_0         718 KB  conda-forge\n",
            "    openssl-3.4.1              |       h7b32b05_0         2.8 MB  conda-forge\n",
            "    p11-kit-0.24.1             |       hc5aa10d_0         4.5 MB  conda-forge\n",
            "    pcre2-10.43                |       hcad00b1_0         929 KB  conda-forge\n",
            "    pixman-0.44.2              |       h29eaf8c_0         372 KB  conda-forge\n",
            "    pthread-stubs-0.4          |    hb9d3cd8_1002           8 KB  conda-forge\n",
            "    pugixml-1.14               |       h59595ed_0         112 KB  conda-forge\n",
            "    rhash-1.4.5                |       hb9d3cd8_0         183 KB  conda-forge\n",
            "    snappy-1.2.1               |       h8bd8927_1          42 KB  conda-forge\n",
            "    svt-av1-2.1.0              |       hac33072_0         2.5 MB  conda-forge\n",
            "    sysroot_linux-64-2.17      |      h0157908_18        14.5 MB  conda-forge\n",
            "    tbb-2022.0.0               |       hceb3a55_0         174 KB  conda-forge\n",
            "    x264-1!164.3095            |       h166bdaf_2         877 KB  conda-forge\n",
            "    x265-3.5                   |       h924138e_3         3.2 MB  conda-forge\n",
            "    xorg-fixesproto-5.0        |    hb9d3cd8_1003          11 KB  conda-forge\n",
            "    xorg-kbproto-1.0.7         |    hb9d3cd8_1003          30 KB  conda-forge\n",
            "    xorg-libice-1.1.2          |       hb9d3cd8_0          57 KB  conda-forge\n",
            "    xorg-libsm-1.2.5           |       he73a12e_0          27 KB  conda-forge\n",
            "    xorg-libx11-1.8.9          |       h8ee46fc_0         809 KB  conda-forge\n",
            "    xorg-libxau-1.0.12         |       hb9d3cd8_0          14 KB  conda-forge\n",
            "    xorg-libxdmcp-1.1.5        |       hb9d3cd8_0          19 KB  conda-forge\n",
            "    xorg-libxext-1.3.4         |       h0b41bf4_2          49 KB  conda-forge\n",
            "    xorg-libxfixes-5.0.3       |    h7f98852_1004          18 KB  conda-forge\n",
            "    xorg-libxrender-0.9.11     |       hd590300_0          37 KB  conda-forge\n",
            "    xorg-renderproto-0.11.1    |    hb9d3cd8_1003          12 KB  conda-forge\n",
            "    xorg-xextproto-7.3.0       |    hb9d3cd8_1004          30 KB  conda-forge\n",
            "    xorg-xproto-7.0.31         |    hb9d3cd8_1008          72 KB  conda-forge\n",
            "    zlib-1.2.13                |       h4ab18f5_6          91 KB  conda-forge\n",
            "    zstd-1.5.6                 |       ha6fb4c9_0         542 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:       254.9 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  aom                conda-forge/linux-64::aom-3.9.1-hac33072_0 \n",
            "  binutils_impl_lin~ conda-forge/linux-64::binutils_impl_linux-64-2.43-h4bf12b8_2 \n",
            "  cairo              conda-forge/linux-64::cairo-1.18.0-h3faef2a_0 \n",
            "  cmake              conda-forge/linux-64::cmake-3.29.4-h91dbaaa_0 \n",
            "  dav1d              conda-forge/linux-64::dav1d-1.2.1-hd590300_0 \n",
            "  expat              conda-forge/linux-64::expat-2.6.4-h5888daf_0 \n",
            "  ffmpeg             conda-forge/linux-64::ffmpeg-7.0.1-gpl_hb399a10_100 \n",
            "  font-ttf-dejavu-s~ conda-forge/noarch::font-ttf-dejavu-sans-mono-2.37-hab24e00_0 \n",
            "  font-ttf-inconsol~ conda-forge/noarch::font-ttf-inconsolata-3.000-h77eed37_0 \n",
            "  font-ttf-source-c~ conda-forge/noarch::font-ttf-source-code-pro-2.038-h77eed37_0 \n",
            "  font-ttf-ubuntu    conda-forge/noarch::font-ttf-ubuntu-0.83-h77eed37_3 \n",
            "  fontconfig         conda-forge/linux-64::fontconfig-2.14.2-h14ed4e7_0 \n",
            "  fonts-conda-ecosy~ conda-forge/noarch::fonts-conda-ecosystem-1-0 \n",
            "  fonts-conda-forge  conda-forge/noarch::fonts-conda-forge-1-0 \n",
            "  freetype           conda-forge/linux-64::freetype-2.12.1-h267a509_2 \n",
            "  fribidi            conda-forge/linux-64::fribidi-1.0.10-h36c2ea0_0 \n",
            "  gcc                conda-forge/linux-64::gcc-14.2.0-h96c4ede_1 \n",
            "  gcc_impl_linux-64  conda-forge/linux-64::gcc_impl_linux-64-14.2.0-h6b349bd_1 \n",
            "  gettext            conda-forge/linux-64::gettext-0.23.1-h5888daf_0 \n",
            "  gettext-tools      conda-forge/linux-64::gettext-tools-0.23.1-h5888daf_0 \n",
            "  gmp                conda-forge/linux-64::gmp-6.3.0-hac33072_2 \n",
            "  gnutls             conda-forge/linux-64::gnutls-3.7.9-hb077bed_0 \n",
            "  graphite2          conda-forge/linux-64::graphite2-1.3.13-h59595ed_1003 \n",
            "  gxx                conda-forge/linux-64::gxx-14.2.0-h96c4ede_1 \n",
            "  gxx_impl_linux-64  conda-forge/linux-64::gxx_impl_linux-64-14.2.0-h2c03514_1 \n",
            "  harfbuzz           conda-forge/linux-64::harfbuzz-8.5.0-hfac3d4d_0 \n",
            "  kernel-headers_li~ conda-forge/noarch::kernel-headers_linux-64-3.10.0-he073ed8_18 \n",
            "  lame               conda-forge/linux-64::lame-3.100-h166bdaf_1003 \n",
            "  libabseil          conda-forge/linux-64::libabseil-20240116.2-cxx17_he02047a_1 \n",
            "  libasprintf        conda-forge/linux-64::libasprintf-0.23.1-h8e693c7_0 \n",
            "  libasprintf-devel  conda-forge/linux-64::libasprintf-devel-0.23.1-h8e693c7_0 \n",
            "  libass             conda-forge/linux-64::libass-0.17.1-h8fe9dca_1 \n",
            "  libdrm             conda-forge/linux-64::libdrm-2.4.124-hb9d3cd8_0 \n",
            "  libexpat           conda-forge/linux-64::libexpat-2.6.4-h5888daf_0 \n",
            "  libgcc             conda-forge/linux-64::libgcc-14.2.0-h77fa898_1 \n",
            "  libgcc-devel_linu~ conda-forge/noarch::libgcc-devel_linux-64-14.2.0-h41c2201_101 \n",
            "  libgettextpo       conda-forge/linux-64::libgettextpo-0.23.1-h5888daf_0 \n",
            "  libgettextpo-devel conda-forge/linux-64::libgettextpo-devel-0.23.1-h5888daf_0 \n",
            "  libglib            conda-forge/linux-64::libglib-2.80.2-hf974151_0 \n",
            "  libhwloc           conda-forge/linux-64::libhwloc-2.11.2-default_he43201b_1000 \n",
            "  libiconv           conda-forge/linux-64::libiconv-1.17-hd590300_2 \n",
            "  libidn2            conda-forge/linux-64::libidn2-2.3.7-hd590300_0 \n",
            "  libopenvino        conda-forge/linux-64::libopenvino-2024.1.0-h2da1b83_7 \n",
            "  libopenvino-auto-~ conda-forge/linux-64::libopenvino-auto-batch-plugin-2024.1.0-hb045406_7 \n",
            "  libopenvino-auto-~ conda-forge/linux-64::libopenvino-auto-plugin-2024.1.0-hb045406_7 \n",
            "  libopenvino-heter~ conda-forge/linux-64::libopenvino-hetero-plugin-2024.1.0-h5c03a75_7 \n",
            "  libopenvino-intel~ conda-forge/linux-64::libopenvino-intel-cpu-plugin-2024.1.0-h2da1b83_7 \n",
            "  libopenvino-intel~ conda-forge/linux-64::libopenvino-intel-gpu-plugin-2024.1.0-h2da1b83_7 \n",
            "  libopenvino-intel~ conda-forge/linux-64::libopenvino-intel-npu-plugin-2024.1.0-he02047a_7 \n",
            "  libopenvino-ir-fr~ conda-forge/linux-64::libopenvino-ir-frontend-2024.1.0-h5c03a75_7 \n",
            "  libopenvino-onnx-~ conda-forge/linux-64::libopenvino-onnx-frontend-2024.1.0-h07e8aee_7 \n",
            "  libopenvino-paddl~ conda-forge/linux-64::libopenvino-paddle-frontend-2024.1.0-h07e8aee_7 \n",
            "  libopenvino-pytor~ conda-forge/linux-64::libopenvino-pytorch-frontend-2024.1.0-he02047a_7 \n",
            "  libopenvino-tenso~ conda-forge/linux-64::libopenvino-tensorflow-frontend-2024.1.0-h39126c6_7 \n",
            "  libopenvino-tenso~ conda-forge/linux-64::libopenvino-tensorflow-lite-frontend-2024.1.0-he02047a_7 \n",
            "  libopus            conda-forge/linux-64::libopus-1.3.1-h7f98852_1 \n",
            "  libpciaccess       conda-forge/linux-64::libpciaccess-0.18-hd590300_0 \n",
            "  libpng             conda-forge/linux-64::libpng-1.6.43-h2797004_0 \n",
            "  libprotobuf        conda-forge/linux-64::libprotobuf-4.25.3-h08a7969_0 \n",
            "  libsanitizer       conda-forge/linux-64::libsanitizer-14.2.0-h2a3dede_1 \n",
            "  libstdcxx          conda-forge/linux-64::libstdcxx-14.2.0-hc0a3c3a_1 \n",
            "  libstdcxx-devel_l~ conda-forge/noarch::libstdcxx-devel_linux-64-14.2.0-h41c2201_101 \n",
            "  libtasn1           conda-forge/linux-64::libtasn1-4.20.0-hb9d3cd8_0 \n",
            "  libunistring       conda-forge/linux-64::libunistring-0.9.10-h7f98852_0 \n",
            "  libuuid            conda-forge/linux-64::libuuid-2.38.1-h0b41bf4_0 \n",
            "  libuv              conda-forge/linux-64::libuv-1.50.0-hb9d3cd8_0 \n",
            "  libva              conda-forge/linux-64::libva-2.21.0-h4ab18f5_2 \n",
            "  libvpx             conda-forge/linux-64::libvpx-1.14.1-hac33072_0 \n",
            "  libxcb             conda-forge/linux-64::libxcb-1.15-h0b41bf4_0 \n",
            "  libzlib            conda-forge/linux-64::libzlib-1.2.13-h4ab18f5_6 \n",
            "  lzo                conda-forge/linux-64::lzo-2.10-hd590300_1001 \n",
            "  nettle             conda-forge/linux-64::nettle-3.9.1-h7ab15ed_0 \n",
            "  ocl-icd            conda-forge/linux-64::ocl-icd-2.3.2-hb9d3cd8_2 \n",
            "  opencl-headers     conda-forge/linux-64::opencl-headers-2024.10.24-h5888daf_0 \n",
            "  openh264           conda-forge/linux-64::openh264-2.4.1-h59595ed_0 \n",
            "  p11-kit            conda-forge/linux-64::p11-kit-0.24.1-hc5aa10d_0 \n",
            "  pixman             conda-forge/linux-64::pixman-0.44.2-h29eaf8c_0 \n",
            "  pthread-stubs      conda-forge/linux-64::pthread-stubs-0.4-hb9d3cd8_1002 \n",
            "  pugixml            conda-forge/linux-64::pugixml-1.14-h59595ed_0 \n",
            "  rhash              conda-forge/linux-64::rhash-1.4.5-hb9d3cd8_0 \n",
            "  snappy             conda-forge/linux-64::snappy-1.2.1-h8bd8927_1 \n",
            "  svt-av1            conda-forge/linux-64::svt-av1-2.1.0-hac33072_0 \n",
            "  sysroot_linux-64   conda-forge/noarch::sysroot_linux-64-2.17-h0157908_18 \n",
            "  tbb                conda-forge/linux-64::tbb-2022.0.0-hceb3a55_0 \n",
            "  x264               conda-forge/linux-64::x264-1!164.3095-h166bdaf_2 \n",
            "  x265               conda-forge/linux-64::x265-3.5-h924138e_3 \n",
            "  xorg-fixesproto    conda-forge/linux-64::xorg-fixesproto-5.0-hb9d3cd8_1003 \n",
            "  xorg-kbproto       conda-forge/linux-64::xorg-kbproto-1.0.7-hb9d3cd8_1003 \n",
            "  xorg-libice        conda-forge/linux-64::xorg-libice-1.1.2-hb9d3cd8_0 \n",
            "  xorg-libsm         conda-forge/linux-64::xorg-libsm-1.2.5-he73a12e_0 \n",
            "  xorg-libx11        conda-forge/linux-64::xorg-libx11-1.8.9-h8ee46fc_0 \n",
            "  xorg-libxau        conda-forge/linux-64::xorg-libxau-1.0.12-hb9d3cd8_0 \n",
            "  xorg-libxdmcp      conda-forge/linux-64::xorg-libxdmcp-1.1.5-hb9d3cd8_0 \n",
            "  xorg-libxext       conda-forge/linux-64::xorg-libxext-1.3.4-h0b41bf4_2 \n",
            "  xorg-libxfixes     conda-forge/linux-64::xorg-libxfixes-5.0.3-h7f98852_1004 \n",
            "  xorg-libxrender    conda-forge/linux-64::xorg-libxrender-0.9.11-hd590300_0 \n",
            "  xorg-renderproto   conda-forge/linux-64::xorg-renderproto-0.11.1-hb9d3cd8_1003 \n",
            "  xorg-xextproto     conda-forge/linux-64::xorg-xextproto-7.3.0-hb9d3cd8_1004 \n",
            "  xorg-xproto        conda-forge/linux-64::xorg-xproto-7.0.31-hb9d3cd8_1008 \n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates    pkgs/main::ca-certificates-2024.12.31~ --> conda-forge::ca-certificates-2025.1.31-hbcca054_0 \n",
            "  icu                        pkgs/main::icu-73.1-h6a678d5_0 --> conda-forge::icu-73.2-h59595ed_0 \n",
            "  ld_impl_linux-64   pkgs/main::ld_impl_linux-64-2.38-h118~ --> conda-forge::ld_impl_linux-64-2.43-h712a8e2_2 \n",
            "  libarchive         pkgs/main::libarchive-3.6.2-h6ac8c49_2 --> conda-forge::libarchive-3.7.4-hfca40fe_0 \n",
            "  libcurl                                  8.4.0-h251f7ec_1 --> 8.12.0-hc9e6f67_0 \n",
            "  libgcc-ng          pkgs/main::libgcc-ng-11.2.0-h1234567_1 --> conda-forge::libgcc-ng-14.2.0-h69a702a_1 \n",
            "  libgomp              pkgs/main::libgomp-11.2.0-h1234567_1 --> conda-forge::libgomp-14.2.0-h77fa898_1 \n",
            "  libmamba                                 1.5.3-haf1ee3a_0 --> 1.5.11-hfe524e5_0 \n",
            "  libmambapy                           1.5.3-py39h2dafd23_0 --> 1.5.11-py39haf1ee3a_0 \n",
            "  libsolv              pkgs/main::libsolv-0.7.24-he621ea3_0 --> conda-forge::libsolv-0.7.29-ha6fb4c9_0 \n",
            "  libssh2                                 1.10.0-hdbd6064_2 --> 1.11.1-h251f7ec_0 \n",
            "  libstdcxx-ng       pkgs/main::libstdcxx-ng-11.2.0-h12345~ --> conda-forge::libstdcxx-ng-14.2.0-h4852527_1 \n",
            "  libxml2              pkgs/main::libxml2-2.10.4-hf1b16e4_1 --> conda-forge::libxml2-2.12.7-hc051c1a_1 \n",
            "  ncurses                 pkgs/main::ncurses-6.4-h6a678d5_0 --> conda-forge::ncurses-6.5-h2d0b736_3 \n",
            "  openssl              pkgs/main::openssl-3.0.15-h5eee18b_0 --> conda-forge::openssl-3.4.1-h7b32b05_0 \n",
            "  pcre2                   pkgs/main::pcre2-10.42-hebb0a14_0 --> conda-forge::pcre2-10.43-hcad00b1_0 \n",
            "  zlib                    pkgs/main::zlib-1.2.13-h5eee18b_0 --> conda-forge::zlib-1.2.13-h4ab18f5_6 \n",
            "  zstd                     pkgs/main::zstd-1.5.5-hc292b87_0 --> conda-forge::zstd-1.5.6-ha6fb4c9_0 \n",
            "\n",
            "The following packages will be SUPERSEDED by a higher-priority channel:\n",
            "\n",
            "  _libgcc_mutex           pkgs/main::_libgcc_mutex-0.1-main --> conda-forge::_libgcc_mutex-0.1-conda_forge \n",
            "  _openmp_mutex          pkgs/main::_openmp_mutex-5.1-1_gnu --> conda-forge::_openmp_mutex-4.5-2_gnu \n",
            "  certifi            pkgs/main/linux-64::certifi-2025.1.31~ --> conda-forge/noarch::certifi-2025.1.31-pyhd8ed1ab_0 \n",
            "\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "Ignoring onnxruntime: markers 'sys_platform == \"darwin\"' don't match your environment\n",
            "Ignoring opencc: markers 'sys_platform != \"linux\"' don't match your environment\n",
            "Collecting numpy==1.23.4 (from -r requirements.txt (line 1))\n",
            "  Downloading numpy-1.23.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Collecting scipy (from -r requirements.txt (line 2))\n",
            "  Downloading scipy-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard (from -r requirements.txt (line 3))\n",
            "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting librosa==0.9.2 (from -r requirements.txt (line 4))\n",
            "  Downloading librosa-0.9.2-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting numba==0.56.4 (from -r requirements.txt (line 5))\n",
            "  Downloading numba-0.56.4-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
            "Collecting pytorch-lightning (from -r requirements.txt (line 6))\n",
            "  Downloading pytorch_lightning-2.5.0.post0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting gradio<=4.24.0,>=4.0 (from -r requirements.txt (line 7))\n",
            "  Downloading gradio-4.24.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting ffmpeg-python (from -r requirements.txt (line 8))\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting onnxruntime-gpu (from -r requirements.txt (line 10))\n",
            "  Downloading onnxruntime_gpu-1.19.2-cp39-cp39-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 11)) (4.65.0)\n",
            "Collecting funasr==1.0.27 (from -r requirements.txt (line 12))\n",
            "  Downloading funasr-1.0.27-py3-none-any.whl.metadata (26 kB)\n",
            "Collecting cn2an (from -r requirements.txt (line 13))\n",
            "  Downloading cn2an-0.5.23-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pypinyin (from -r requirements.txt (line 14))\n",
            "  Downloading pypinyin-0.53.0-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting pyopenjtalk>=0.3.4 (from -r requirements.txt (line 15))\n",
            "  Downloading pyopenjtalk-0.4.0.tar.gz (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting g2p_en (from -r requirements.txt (line 16))\n",
            "  Downloading g2p_en-2.1.0-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting torchaudio (from -r requirements.txt (line 17))\n",
            "  Downloading torchaudio-2.6.0-cp39-cp39-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting modelscope==1.10.0 (from -r requirements.txt (line 18))\n",
            "  Downloading modelscope-1.10.0-py3-none-any.whl.metadata (33 kB)\n",
            "Collecting sentencepiece (from -r requirements.txt (line 19))\n",
            "  Downloading sentencepiece-0.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting transformers (from -r requirements.txt (line 20))\n",
            "  Downloading transformers-4.48.3-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chardet (from -r requirements.txt (line 21))\n",
            "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting PyYAML (from -r requirements.txt (line 22))\n",
            "  Downloading PyYAML-6.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting psutil (from -r requirements.txt (line 23))\n",
            "  Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting jieba_fast (from -r requirements.txt (line 24))\n",
            "  Downloading jieba_fast-0.53.tar.gz (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jieba (from -r requirements.txt (line 25))\n",
            "  Downloading jieba-0.42.1.tar.gz (19.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting split-lang (from -r requirements.txt (line 26))\n",
            "  Downloading split_lang-2.0.5-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting Faster_Whisper (from -r requirements.txt (line 27))\n",
            "  Downloading faster_whisper-1.1.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting wordsegment (from -r requirements.txt (line 28))\n",
            "  Downloading wordsegment-1.3.1-py2.py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting rotary_embedding_torch (from -r requirements.txt (line 29))\n",
            "  Downloading rotary_embedding_torch-0.8.6-py3-none-any.whl.metadata (675 bytes)\n",
            "Collecting ToJyutping (from -r requirements.txt (line 30))\n",
            "  Downloading ToJyutping-3.2.0-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting g2pk2 (from -r requirements.txt (line 31))\n",
            "  Downloading g2pk2-0.0.3-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting ko_pron (from -r requirements.txt (line 32))\n",
            "  Downloading ko_pron-1.3-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting opencc==1.1.1 (from -r requirements.txt (line 34))\n",
            "  Downloading OpenCC-1.1.1-py2.py3-none-manylinux1_x86_64.whl.metadata (10 kB)\n",
            "Collecting python_mecab_ko (from -r requirements.txt (line 35))\n",
            "  Downloading python_mecab_ko-1.3.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting fastapi<0.112.2 (from -r requirements.txt (line 36))\n",
            "  Downloading fastapi-0.112.1-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting x_transformers (from -r requirements.txt (line 37))\n",
            "  Downloading x_transformers-2.0.4-py3-none-any.whl.metadata (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.9/86.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchmetrics==1.5 (from -r requirements.txt (line 38))\n",
            "  Downloading torchmetrics-1.5.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting audioread>=2.1.9 (from librosa==0.9.2->-r requirements.txt (line 4))\n",
            "  Downloading audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting scikit-learn>=0.19.1 (from librosa==0.9.2->-r requirements.txt (line 4))\n",
            "  Downloading scikit_learn-1.6.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting joblib>=0.14 (from librosa==0.9.2->-r requirements.txt (line 4))\n",
            "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting decorator>=4.0.10 (from librosa==0.9.2->-r requirements.txt (line 4))\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting resampy>=0.2.2 (from librosa==0.9.2->-r requirements.txt (line 4))\n",
            "  Downloading resampy-0.4.3-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting soundfile>=0.10.2 (from librosa==0.9.2->-r requirements.txt (line 4))\n",
            "  Downloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (16 kB)\n",
            "Collecting pooch>=1.0 (from librosa==0.9.2->-r requirements.txt (line 4))\n",
            "  Downloading pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/site-packages (from librosa==0.9.2->-r requirements.txt (line 4)) (23.1)\n",
            "Collecting llvmlite<0.40,>=0.39.0dev0 (from numba==0.56.4->-r requirements.txt (line 5))\n",
            "  Downloading llvmlite-0.39.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/site-packages (from numba==0.56.4->-r requirements.txt (line 5)) (68.2.2)\n",
            "Collecting jamo (from funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading jamo-0.4.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting kaldiio>=2.17.0 (from funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading kaldiio-2.18.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting torch-complex (from funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading torch_complex-0.4.4-py3-none-any.whl.metadata (3.1 kB)\n",
            "Collecting pytorch-wpe (from funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading pytorch_wpe-0.0.1-py3-none-any.whl.metadata (242 bytes)\n",
            "Collecting editdistance>=0.5.2 (from funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading editdistance-0.8.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
            "Collecting oss2 (from funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading oss2-2.19.1.tar.gz (298 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.8/298.8 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting umap-learn (from funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading umap_learn-0.5.7-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting jaconv (from funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading jaconv-0.4.0.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting hydra-core>=1.3.2 (from funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting tensorboardX (from funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting openai-whisper (from funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading openai-whisper-20240930.tar.gz (800 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting addict (from modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting attrs (from modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading attrs-25.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting datasets>=2.14.5 (from modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading datasets-3.3.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting einops (from modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting filelock>=3.3.0 (from modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gast>=0.2.2 (from modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting pandas (from modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading pandas-2.2.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pillow>=6.2.0 (from modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading pillow-11.1.0-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting pyarrow!=9.0.0,>=6.0.0 (from modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading pyarrow-19.0.0-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting python-dateutil>=2.1 (from modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: requests>=2.25 in /usr/local/lib/python3.9/site-packages (from modelscope==1.10.0->-r requirements.txt (line 18)) (2.31.0)\n",
            "Collecting simplejson>=3.3.0 (from modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading simplejson-3.20.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Collecting sortedcontainers>=1.5.9 (from modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.9/site-packages (from modelscope==1.10.0->-r requirements.txt (line 18)) (1.26.18)\n",
            "Collecting yapf (from modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading yapf-0.43.0-py3-none-any.whl.metadata (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch>=1.10.0 (from torchmetrics==1.5->-r requirements.txt (line 38))\n",
            "  Downloading torch-2.6.0-cp39-cp39-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics==1.5->-r requirements.txt (line 38))\n",
            "  Downloading lightning_utilities-0.12.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting absl-py>=0.4 (from tensorboard->-r requirements.txt (line 3))\n",
            "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting grpcio>=1.48.2 (from tensorboard->-r requirements.txt (line 3))\n",
            "  Downloading grpcio-1.70.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
            "Collecting markdown>=2.6.8 (from tensorboard->-r requirements.txt (line 3))\n",
            "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting protobuf!=4.24.0,>=3.19.6 (from tensorboard->-r requirements.txt (line 3))\n",
            "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting six>1.9 (from tensorboard->-r requirements.txt (line 3))\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard->-r requirements.txt (line 3))\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard->-r requirements.txt (line 3))\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting fsspec>=2022.5.0 (from fsspec[http]>=2022.5.0->pytorch-lightning->-r requirements.txt (line 6))\n",
            "  Downloading fsspec-2025.2.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting typing-extensions>=4.4.0 (from pytorch-lightning->-r requirements.txt (line 6))\n",
            "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting altair<6.0,>=4.2.0 (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting ffmpy (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==0.14.0 (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading gradio_client-0.14.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting httpx>=0.24.1 (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting huggingface-hub>=0.19.3 (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading huggingface_hub-0.28.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting importlib-resources<7.0,>=1.3 (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting jinja2<4.0 (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting markupsafe~=2.0 (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading MarkupSafe-2.1.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting matplotlib~=3.0 (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading matplotlib-3.9.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting orjson~=3.0 (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading orjson-3.10.15-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pillow>=6.2.0 (from modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading pillow-10.4.0-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting pydantic>=2.0 (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting pydub (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting ruff>=0.2.2 (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading ruff-0.9.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting typer<1.0,>=0.9 (from typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading typer-0.15.1-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting uvicorn>=0.14.0 (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==0.14.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading websockets-11.0.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting future (from ffmpeg-python->-r requirements.txt (line 8))\n",
            "  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting coloredlogs (from onnxruntime-gpu->-r requirements.txt (line 10))\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting flatbuffers (from onnxruntime-gpu->-r requirements.txt (line 10))\n",
            "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Collecting sympy (from onnxruntime-gpu->-r requirements.txt (line 10))\n",
            "  Downloading sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting proces>=0.1.7 (from cn2an->-r requirements.txt (line 13))\n",
            "  Downloading proces-0.1.7-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting nltk>=3.2.4 (from g2p_en->-r requirements.txt (line 16))\n",
            "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting inflect>=0.3.1 (from g2p_en->-r requirements.txt (line 16))\n",
            "  Downloading inflect-7.5.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting distance>=0.1.3 (from g2p_en->-r requirements.txt (line 16))\n",
            "  Downloading Distance-0.1.3.tar.gz (180 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.3/180.3 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting networkx (from torch>=1.10.0->torchmetrics==1.5->-r requirements.txt (line 38))\n",
            "  Downloading networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.10.0->torchmetrics==1.5->-r requirements.txt (line 38))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.10.0->torchmetrics==1.5->-r requirements.txt (line 38))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.10.0->torchmetrics==1.5->-r requirements.txt (line 38))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.10.0->torchmetrics==1.5->-r requirements.txt (line 38))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.10.0->torchmetrics==1.5->-r requirements.txt (line 38))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.10.0->torchmetrics==1.5->-r requirements.txt (line 38))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.10.0->torchmetrics==1.5->-r requirements.txt (line 38))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.10.0->torchmetrics==1.5->-r requirements.txt (line 38))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.10.0->torchmetrics==1.5->-r requirements.txt (line 38))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch>=1.10.0->torchmetrics==1.5->-r requirements.txt (line 38))\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch>=1.10.0->torchmetrics==1.5->-r requirements.txt (line 38))\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from torch>=1.10.0->torchmetrics==1.5->-r requirements.txt (line 38))\n",
            "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.10.0->torchmetrics==1.5->-r requirements.txt (line 38))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.2.0 (from torch>=1.10.0->torchmetrics==1.5->-r requirements.txt (line 38))\n",
            "  Downloading triton-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting sympy (from onnxruntime-gpu->-r requirements.txt (line 10))\n",
            "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy->onnxruntime-gpu->-r requirements.txt (line 10))\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting regex!=2019.12.17 (from transformers->-r requirements.txt (line 20))\n",
            "  Downloading regex-2024.11.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers<0.22,>=0.21 (from transformers->-r requirements.txt (line 20))\n",
            "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting safetensors>=0.4.1 (from transformers->-r requirements.txt (line 20))\n",
            "  Downloading safetensors-0.5.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting fast-langdetect (from split-lang->-r requirements.txt (line 26))\n",
            "  Downloading fast_langdetect-0.2.5-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting budoux (from split-lang->-r requirements.txt (line 26))\n",
            "  Downloading budoux-0.6.4-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting wordfreq (from split-lang->-r requirements.txt (line 26))\n",
            "  Downloading wordfreq-3.1.1-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ctranslate2<5,>=4.0 (from Faster_Whisper->-r requirements.txt (line 27))\n",
            "  Downloading ctranslate2-4.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting onnxruntime<2,>=1.14 (from Faster_Whisper->-r requirements.txt (line 27))\n",
            "  Downloading onnxruntime-1.19.2-cp39-cp39-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting av>=11 (from Faster_Whisper->-r requirements.txt (line 27))\n",
            "  Downloading av-14.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
            "Collecting python-mecab-ko-dic (from python_mecab_ko->-r requirements.txt (line 35))\n",
            "  Downloading python_mecab_ko_dic-2.1.1.post2-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting starlette<0.39.0,>=0.37.2 (from fastapi<0.112.2->-r requirements.txt (line 36))\n",
            "  Downloading starlette-0.38.6-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting einx>=0.3.0 (from x_transformers->-r requirements.txt (line 37))\n",
            "  Downloading einx-0.3.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting loguru (from x_transformers->-r requirements.txt (line 37))\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jsonschema>=3.0 (from altair<6.0,>=4.2.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting narwhals>=1.14.2 (from altair<6.0,>=4.2.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading narwhals-1.26.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting requests>=2.25 (from modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting tqdm (from -r requirements.txt (line 11))\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading xxhash-3.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading multiprocess-0.70.16-py39-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec>=2022.5.0 (from fsspec[http]>=2022.5.0->pytorch-lightning->-r requirements.txt (line 6))\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting aiohttp (from datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading aiohttp-3.11.12-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: frozendict in /usr/local/lib/python3.9/site-packages (from einx>=0.3.0->x_transformers->-r requirements.txt (line 37)) (2.4.2)\n",
            "Collecting anyio (from httpx>=0.24.1->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading anyio-4.8.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.9/site-packages (from httpx>=0.24.1->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (2025.1.31)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.9/site-packages (from httpx>=0.24.1->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (3.4)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting omegaconf<2.4,>=2.2 (from hydra-core>=1.3.2->funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.3.2->funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting zipp>=3.1.0 (from importlib-resources<7.0,>=1.3->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting more_itertools>=8.5.0 (from inflect>=0.3.1->g2p_en->-r requirements.txt (line 16))\n",
            "  Downloading more_itertools-10.6.0-py3-none-any.whl.metadata (37 kB)\n",
            "Collecting typeguard>=4.0.1 (from inflect>=0.3.1->g2p_en->-r requirements.txt (line 16))\n",
            "  Downloading typeguard-4.4.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting importlib-metadata>=4.4 (from markdown>=2.6.8->tensorboard->-r requirements.txt (line 3))\n",
            "  Downloading importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib~=3.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading contourpy-1.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib~=3.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib~=3.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading fonttools-4.56.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.9/101.9 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib~=3.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading kiwisolver-1.4.7-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)\n",
            "Collecting pyparsing>=2.3.1 (from matplotlib~=3.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting click (from nltk>=3.2.4->g2p_en->-r requirements.txt (line 16))\n",
            "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting pytz>=2020.1 (from pandas->modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas->modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.9/site-packages (from pooch>=1.0->librosa==0.9.2->-r requirements.txt (line 4)) (3.10.0)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic>=2.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.27.2 (from pydantic>=2.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading pydantic_core-2.27.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/site-packages (from requests>=2.25->modelscope==1.10.0->-r requirements.txt (line 18)) (2.0.4)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=0.19.1->librosa==0.9.2->-r requirements.txt (line 4))\n",
            "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.9/site-packages (from soundfile>=0.10.2->librosa==0.9.2->-r requirements.txt (line 4)) (1.16.0)\n",
            "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rich>=10.11.0 (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
            "\u001b[33mWARNING: typer 0.15.1 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime-gpu->-r requirements.txt (line 10))\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting robust-downloader>=0.0.2 (from fast-langdetect->split-lang->-r requirements.txt (line 26))\n",
            "  Downloading robust_downloader-0.0.2-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting fasttext-predict>=0.9.2.4 (from fast-langdetect->split-lang->-r requirements.txt (line 26))\n",
            "  Downloading fasttext_predict-0.9.2.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting tiktoken (from openai-whisper->funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading tiktoken-0.9.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting crcmod>=1.7 (from oss2->funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pycryptodome>=3.4.7 (from oss2->funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading pycryptodome-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting aliyun-python-sdk-kms>=2.4.1 (from oss2->funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading aliyun_python_sdk_kms-2.16.5-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting aliyun-python-sdk-core>=2.13.12 (from oss2->funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading aliyun-python-sdk-core-2.16.0.tar.gz (449 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m449.6/449.6 kB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pynndescent>=0.5 (from umap-learn->funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting ftfy>=6.1 (from wordfreq->split-lang->-r requirements.txt (line 26))\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting langcodes>=3.0 (from wordfreq->split-lang->-r requirements.txt (line 26))\n",
            "  Downloading langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting locate<2.0.0,>=1.1.1 (from wordfreq->split-lang->-r requirements.txt (line 26))\n",
            "  Downloading locate-1.1.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting msgpack<2.0.0,>=1.0.7 (from wordfreq->split-lang->-r requirements.txt (line 26))\n",
            "  Downloading msgpack-1.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
            "Collecting ipadic<2.0.0,>=1.0.0 (from wordfreq[cjk]->split-lang->-r requirements.txt (line 26))\n",
            "  Downloading ipadic-1.0.0.tar.gz (13.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m98.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mecab-ko-dic<2.0.0,>=1.0.0 (from wordfreq[cjk]->split-lang->-r requirements.txt (line 26))\n",
            "  Downloading mecab-ko-dic-1.0.0.tar.gz (33.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.2/33.2 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mecab-python3<2.0.0,>=1.0.5 (from wordfreq[cjk]->split-lang->-r requirements.txt (line 26))\n",
            "  Downloading mecab_python3-1.0.10-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
            "Collecting tomli>=2.0.1 (from yapf->modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Using cached tomli-2.2.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading aiohappyeyeballs-2.4.6-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.1.2 (from aiohttp->datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting async-timeout<6.0,>=4.0 (from aiohttp->datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp->datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading frozenlist-1.5.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading multidict-6.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp->datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading propcache-0.2.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading yarl-1.18.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.2/69.2 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.9.3 (from aliyun-python-sdk-core>=2.13.12->oss2->funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: cryptography>=3.0.0 in /usr/local/lib/python3.9/site-packages (from aliyun-python-sdk-core>=2.13.12->oss2->funasr==1.0.27->-r requirements.txt (line 12)) (41.0.7)\n",
            "Collecting exceptiongroup>=1.0.2 (from anyio->httpx>=0.24.1->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading exceptiongroup-1.2.2-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting sniffio>=1.1 (from anyio->httpx>=0.24.1->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa==0.9.2->-r requirements.txt (line 4)) (2.21)\n",
            "Collecting wcwidth (from ftfy>=6.1->wordfreq->split-lang->-r requirements.txt (line 26))\n",
            "  Downloading wcwidth-0.2.13-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting referencing>=0.28.4 (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting rpds-py>=0.7.1 (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading rpds_py-0.22.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Collecting language-data>=1.2 (from langcodes>=3.0->wordfreq->split-lang->-r requirements.txt (line 26))\n",
            "  Downloading language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting pygments<3.0.0,>=2.13.0 (from rich>=10.11.0->typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading pygments-2.19.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting colorlog (from robust-downloader>=0.0.2->fast-langdetect->split-lang->-r requirements.txt (line 26))\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes>=3.0->wordfreq->split-lang->-r requirements.txt (line 26))\n",
            "  Downloading marisa_trie-1.2.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Downloading numpy-1.23.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m102.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading librosa-0.9.2-py3-none-any.whl (214 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.3/214.3 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numba-0.56.4-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading funasr-1.0.27-py3-none-any.whl (693 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m693.7/693.7 kB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading modelscope-1.10.0-py3-none-any.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading OpenCC-1.1.1-py2.py3-none-manylinux1_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.5.0-py3-none-any.whl (890 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m890.5/890.5 kB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.5.0.post0-py3-none-any.whl (819 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.3/819.3 kB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-4.24.0-py3-none-any.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-0.14.0-py3-none-any.whl (312 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.4/312.4 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Downloading onnxruntime_gpu-1.19.2-cp39-cp39-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (226.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.2/226.2 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cn2an-0.5.23-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.9/224.9 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypinyin-0.53.0-py2.py3-none-any.whl (834 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m834.7/834.7 kB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading g2p_en-2.1.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchaudio-2.6.0-cp39-cp39-manylinux1_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.6.0-cp39-cp39-manylinux1_x86_64.whl (766.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m101.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m765.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m85.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.1/253.1 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentencepiece-0.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.48.3-py3-none-any.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m97.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyYAML-6.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (737 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m737.4/737.4 kB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (277 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.0/278.0 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading split_lang-2.0.5-py3-none-any.whl (27 kB)\n",
            "Downloading faster_whisper-1.1.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wordsegment-1.3.1-py2.py3-none-any.whl (4.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m97.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rotary_embedding_torch-0.8.6-py3-none-any.whl (5.6 kB)\n",
            "Downloading ToJyutping-3.2.0-py3-none-any.whl (287 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.9/287.9 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading g2pk2-0.0.3-py3-none-any.whl (25 kB)\n",
            "Downloading ko_pron-1.3-py3-none-any.whl (12 kB)\n",
            "Downloading python_mecab_ko-1.3.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m578.6/578.6 kB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.112.1-py3-none-any.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading x_transformers-2.0.4-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.5/75.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading altair-5.5.0-py3-none-any.whl (731 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.2/731.2 kB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading audioread-3.0.1-py3-none-any.whl (23 kB)\n",
            "Downloading av-14.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.8/38.8 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ctranslate2-4.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.3.0-py3-none-any.whl (484 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m484.9/484.9 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Downloading editdistance-0.8.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (401 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.6/401.6 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.4/64.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading einx-0.3.0-py3-none-any.whl (102 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.0/103.0 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.17.0-py3-none-any.whl (16 kB)\n",
            "Downloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
            "Downloading grpcio-1.70.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m97.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.28.1-py3-none-any.whl (464 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m464.1/464.1 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
            "Downloading inflect-7.5.0-py3-none-any.whl (35 kB)\n",
            "Downloading jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.6/134.6 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kaldiio-2.18.0-py3-none-any.whl (28 kB)\n",
            "Downloading lightning_utilities-0.12.0-py3-none-any.whl (28 kB)\n",
            "Downloading llvmlite-0.39.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.6/34.6 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading matplotlib-3.9.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.19.2-cp39-cp39-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.15-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.1/130.1 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.2.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m97.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-10.4.0-cp39-cp39-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m88.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.6/64.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading proces-0.1.7-py3-none-any.whl (137 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.7/137.7 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-19.0.0-cp39-cp39-manylinux_2_28_x86_64.whl (42.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.7/431.7 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.27.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading regex-2024.11.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (780 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.9/780.9 kB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruff-0.9.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safetensors-0.5.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (461 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.0/462.0 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.6.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading simplejson-3.20.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.4/137.4 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Downloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.38.6-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typer-0.15.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading attrs-25.1.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.2/63.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading budoux-0.6.4-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.6/118.6 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fast_langdetect-0.2.5-py3-none-any.whl (786 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m786.6/786.6 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
            "Downloading future-1.0.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.3/491.3 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jamo-0.4.1-py3-none-any.whl (9.5 kB)\n",
            "Downloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading python_mecab_ko_dic-2.1.1.post2-py3-none-any.whl (34.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_wpe-0.0.1-py3-none-any.whl (8.1 kB)\n",
            "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_complex-0.4.4-py3-none-any.whl (9.1 kB)\n",
            "Downloading umap_learn-0.5.7-py3-none-any.whl (88 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.8/88.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wordfreq-3.1.1-py3-none-any.whl (56.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yapf-0.43.0-py3-none-any.whl (256 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.2/256.2 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp-3.11.12-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aliyun_python_sdk_kms-2.16.5-py2.py3-none-any.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.5/99.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Downloading anyio-4.8.0-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.0/96.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.1.8-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading contourpy-1.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (321 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.9/321.9 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fasttext_predict-0.9.2.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.2/294.2 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fonttools-4.56.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
            "Downloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.5/88.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kiwisolver-1.4.7-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.0/183.0 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading locate-1.1.1-py3-none-any.whl (5.4 kB)\n",
            "Downloading mecab_python3-1.0.10-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (581 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m581.6/581.6 kB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading more_itertools-10.6.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msgpack-1.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (377 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.9/377.9 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py39-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading narwhals-1.26.0-py3-none-any.whl (306 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m306.6/306.6 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycryptodome-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.7/107.7 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.9/507.9 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading robust_downloader-0.0.2-py3-none-any.whl (15 kB)\n",
            "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
            "Using cached tomli-2.2.1-py3-none-any.whl (14 kB)\n",
            "Downloading typeguard-4.4.1-py3-none-any.whl (35 kB)\n",
            "Downloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.8/346.8 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-11.0.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.7/129.7 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
            "Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.9/193.9 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohappyeyeballs-2.4.6-py3-none-any.whl (14 kB)\n",
            "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
            "Downloading exceptiongroup-1.2.2-py3-none-any.whl (16 kB)\n",
            "Downloading frozenlist-1.5.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.9/242.9 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n",
            "Downloading language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multidict-6.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.1/124.1 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading propcache-0.2.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (208 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.3/208.3 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pygments-2.19.1-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
            "Downloading rpds_py-0.22.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (382 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m382.3/382.3 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Downloading yarl-1.18.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (321 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.5/321.5 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\n",
            "Downloading marisa_trie-1.2.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Building wheels for collected packages: pyopenjtalk, jieba_fast, jieba, distance, antlr4-python3-runtime, jaconv, openai-whisper, oss2, aliyun-python-sdk-core, crcmod, ipadic, mecab-ko-dic\n",
            "  Building wheel for pyopenjtalk (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyopenjtalk: filename=pyopenjtalk-0.4.0-cp39-cp39-linux_x86_64.whl size=1286906 sha256=a44cac6baee812154e63ce6d6c71230ea088ee8e82e760b7cd377ba0b53566d4\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/de/f6/3a8847509deeadf0c7460602b4b05a9d0d65026100568a644f\n",
            "  Building wheel for jieba_fast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jieba_fast: filename=jieba_fast-0.53-cp39-cp39-linux_x86_64.whl size=7628765 sha256=37c9cf4497fa1e08782b0602d38f1578ef0f08aaf66da208b9878e3b7962f5f8\n",
            "  Stored in directory: /root/.cache/pip/wheels/b0/04/c8/5c563e7f58588aadfa5af1353a086ef467eb1dadd2fcfac622\n",
            "  Building wheel for jieba (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314458 sha256=23ac300ac1aa9715f583a4f8f5e5a2153a41c2a015f4844be8ec26890b969b44\n",
            "  Stored in directory: /root/.cache/pip/wheels/7d/74/cf/08c94db4b784e2c1ef675a600b7b5b281fd25240dcb954ee7e\n",
            "  Building wheel for distance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for distance: filename=Distance-0.1.3-py3-none-any.whl size=16258 sha256=79362e009c7139b4f9d81d0ccc49ef1dbe02e6e8c501f46cb16e0ff2ba513f4a\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/b3/aa/04241cced6d1722b132273b1d6aafba317887ec004f48b853a\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=42496555a95e038fb9280bfd803c12c9428db91155e19d95f281d71da8f9cd4f\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/cf/80/f3efa822e6ab23277902ee9165fe772eeb1dfb8014f359020a\n",
            "  Building wheel for jaconv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jaconv: filename=jaconv-0.4.0-py3-none-any.whl size=18227 sha256=886dc230673e9aafb2c7f94df92b62b5114bf03222d3d886a32c5257648484df\n",
            "  Stored in directory: /root/.cache/pip/wheels/c6/6b/fa/9574efaca6aced07c97ab08d7e40a5cdf8f31ecbe73d55e077\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803373 sha256=e70d5996a66ac6366c87f117014bd02a0c2824b699c3e4918ae0a9d8de3504b0\n",
            "  Stored in directory: /root/.cache/pip/wheels/94/29/f3/3dd4d7f88df5d701acd3206732dcb6265379c5ece94b472c17\n",
            "  Building wheel for oss2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for oss2: filename=oss2-2.19.1-py3-none-any.whl size=123938 sha256=06340093b1b0ac1e70a8e107072310aef8a52b01195023b66494c72b9db1bbee\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/f9/6e/25b9a00f60e4cc7db56fb53f60546568ac3f697e32e3bff38b\n",
            "  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for aliyun-python-sdk-core: filename=aliyun_python_sdk_core-2.16.0-py3-none-any.whl size=535317 sha256=6720f8e65c19b2e4e00412eee2f23d3ecc9788a904eb4f8bcd5f80efd119dcfb\n",
            "  Stored in directory: /root/.cache/pip/wheels/be/85/b9/f7c05b089e7fad969001438f8a0175c7233a8635b49d5af57e\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp39-cp39-linux_x86_64.whl size=23178 sha256=0c79b6bdddc90d6d43a87b0e7b8ad8aadbc4ed0e530e463f7aa6fe74506e0d36\n",
            "  Stored in directory: /root/.cache/pip/wheels/4a/6c/a6/ffdd136310039bf226f2707a9a8e6857be7d70a3fc061f6b36\n",
            "  Building wheel for ipadic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ipadic: filename=ipadic-1.0.0-py3-none-any.whl size=13556703 sha256=e1ded9c36f96af9f72536fd700d99fd77a4cefc67b08418878f66e801ded1afc\n",
            "  Stored in directory: /root/.cache/pip/wheels/a0/9e/13/a63ab80684c3bd6305fe2bded26ac5f2c72ee1cb07a747994d\n",
            "  Building wheel for mecab-ko-dic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mecab-ko-dic: filename=mecab_ko_dic-1.0.0-py3-none-any.whl size=33424393 sha256=87bb165afe1719523aef8e1efff744bf2ddbb2e45e932cc67eb85d3d29d6192f\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/26/c0/ed4c061096b1480abefe1e2a0356543bf7a38f61c037b69ab6\n",
            "Successfully built pyopenjtalk jieba_fast jieba distance antlr4-python3-runtime jaconv openai-whisper oss2 aliyun-python-sdk-core crcmod ipadic mecab-ko-dic\n",
            "Installing collected packages: wordsegment, wcwidth, triton, sortedcontainers, sentencepiece, pytz, python-mecab-ko-dic, pydub, opencc, nvidia-cusparselt-cu12, mpmath, mecab-python3, mecab-ko-dic, ko_pron, jieba_fast, jieba, jamo, jaconv, ipadic, flatbuffers, fasttext-predict, distance, crcmod, antlr4-python3-runtime, addict, zipp, xxhash, websockets, tzdata, typing-extensions, tqdm, tomlkit, tomli, ToJyutping, threadpoolctl, tensorboard-data-server, sympy, sniffio, six, simplejson, shellingham, semantic-version, safetensors, ruff, rpds-py, requests, regex, PyYAML, python-multipart, python_mecab_ko, pypinyin, pyparsing, pygments, pycryptodome, pyarrow, psutil, protobuf, propcache, proces, Pillow, orjson, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, narwhals, msgpack, more_itertools, mdurl, markupsafe, marisa-trie, loguru, locate, llvmlite, kiwisolver, joblib, jmespath, humanfriendly, h11, grpcio, gast, future, ftfy, fsspec, frozenlist, fonttools, filelock, ffmpy, exceptiongroup, einops, editdistance, dill, decorator, cycler, colorlog, click, chardet, av, audioread, attrs, async-timeout, annotated-types, aiohappyeyeballs, aiofiles, absl-py, yapf, werkzeug, uvicorn, torch-complex, tiktoken, tensorboardX, soundfile, scipy, robust-downloader, referencing, pytorch-wpe, python-dateutil, pyopenjtalk, pydantic-core, pooch, omegaconf, nvidia-cusparse-cu12, nvidia-cudnn-cu12, numba, nltk, multiprocess, multidict, markdown-it-py, lightning-utilities, language-data, kaldiio, jinja2, importlib-resources, importlib-metadata, huggingface-hub, httpcore, ffmpeg-python, einx, ctranslate2, contourpy, coloredlogs, cn2an, anyio, aiosignal, yarl, typeguard, tokenizers, starlette, scikit-learn, rich, resampy, pydantic, pandas, onnxruntime-gpu, onnxruntime, nvidia-cusolver-cu12, matplotlib, markdown, langcodes, jsonschema-specifications, hydra-core, httpx, g2pk2, fast-langdetect, budoux, aliyun-python-sdk-core, wordfreq, typer, transformers, torch, tensorboard, pynndescent, librosa, jsonschema, inflect, gradio-client, Faster_Whisper, fastapi, aliyun-python-sdk-kms, aiohttp, x_transformers, umap-learn, torchmetrics, torchaudio, rotary_embedding_torch, oss2, openai-whisper, g2p_en, altair, split-lang, pytorch-lightning, gradio, funasr, datasets, modelscope\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.65.0\n",
            "    Uninstalling tqdm-4.65.0:\n",
            "      Successfully uninstalled tqdm-4.65.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "Successfully installed Faster_Whisper-1.1.1 Pillow-10.4.0 PyYAML-6.0.2 ToJyutping-3.2.0 absl-py-2.1.0 addict-2.4.0 aiofiles-23.2.1 aiohappyeyeballs-2.4.6 aiohttp-3.11.12 aiosignal-1.3.2 aliyun-python-sdk-core-2.16.0 aliyun-python-sdk-kms-2.16.5 altair-5.5.0 annotated-types-0.7.0 antlr4-python3-runtime-4.9.3 anyio-4.8.0 async-timeout-5.0.1 attrs-25.1.0 audioread-3.0.1 av-14.1.0 budoux-0.6.4 chardet-5.2.0 click-8.1.8 cn2an-0.5.23 coloredlogs-15.0.1 colorlog-6.9.0 contourpy-1.3.0 crcmod-1.7 ctranslate2-4.5.0 cycler-0.12.1 datasets-3.3.0 decorator-5.1.1 dill-0.3.8 distance-0.1.3 editdistance-0.8.1 einops-0.8.1 einx-0.3.0 exceptiongroup-1.2.2 fast-langdetect-0.2.5 fastapi-0.112.1 fasttext-predict-0.9.2.4 ffmpeg-python-0.2.0 ffmpy-0.5.0 filelock-3.17.0 flatbuffers-25.2.10 fonttools-4.56.0 frozenlist-1.5.0 fsspec-2024.12.0 ftfy-6.3.1 funasr-1.0.27 future-1.0.0 g2p_en-2.1.0 g2pk2-0.0.3 gast-0.6.0 gradio-4.24.0 gradio-client-0.14.0 grpcio-1.70.0 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 huggingface-hub-0.28.1 humanfriendly-10.0 hydra-core-1.3.2 importlib-metadata-8.6.1 importlib-resources-6.5.2 inflect-7.5.0 ipadic-1.0.0 jaconv-0.4.0 jamo-0.4.1 jieba-0.42.1 jieba_fast-0.53 jinja2-3.1.5 jmespath-0.10.0 joblib-1.4.2 jsonschema-4.23.0 jsonschema-specifications-2024.10.1 kaldiio-2.18.0 kiwisolver-1.4.7 ko_pron-1.3 langcodes-3.5.0 language-data-1.3.0 librosa-0.9.2 lightning-utilities-0.12.0 llvmlite-0.39.1 locate-1.1.1 loguru-0.7.3 marisa-trie-1.2.1 markdown-3.7 markdown-it-py-3.0.0 markupsafe-2.1.5 matplotlib-3.9.4 mdurl-0.1.2 mecab-ko-dic-1.0.0 mecab-python3-1.0.10 modelscope-1.10.0 more_itertools-10.6.0 mpmath-1.3.0 msgpack-1.1.0 multidict-6.1.0 multiprocess-0.70.16 narwhals-1.26.0 networkx-3.2.1 nltk-3.9.1 numba-0.56.4 numpy-1.23.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 omegaconf-2.3.0 onnxruntime-1.19.2 onnxruntime-gpu-1.19.2 openai-whisper-20240930 opencc-1.1.1 orjson-3.10.15 oss2-2.19.1 pandas-2.2.3 pooch-1.8.2 proces-0.1.7 propcache-0.2.1 protobuf-5.29.3 psutil-7.0.0 pyarrow-19.0.0 pycryptodome-3.21.0 pydantic-2.10.6 pydantic-core-2.27.2 pydub-0.25.1 pygments-2.19.1 pynndescent-0.5.13 pyopenjtalk-0.4.0 pyparsing-3.2.1 pypinyin-0.53.0 python-dateutil-2.9.0.post0 python-mecab-ko-dic-2.1.1.post2 python-multipart-0.0.20 python_mecab_ko-1.3.7 pytorch-lightning-2.5.0.post0 pytorch-wpe-0.0.1 pytz-2025.1 referencing-0.36.2 regex-2024.11.6 requests-2.32.3 resampy-0.4.3 rich-13.9.4 robust-downloader-0.0.2 rotary_embedding_torch-0.8.6 rpds-py-0.22.3 ruff-0.9.6 safetensors-0.5.2 scikit-learn-1.6.1 scipy-1.13.1 semantic-version-2.10.0 sentencepiece-0.2.0 shellingham-1.5.4 simplejson-3.20.1 six-1.17.0 sniffio-1.3.1 sortedcontainers-2.4.0 soundfile-0.13.1 split-lang-2.0.5 starlette-0.38.6 sympy-1.13.1 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorboardX-2.6.2.2 threadpoolctl-3.5.0 tiktoken-0.9.0 tokenizers-0.21.0 tomli-2.2.1 tomlkit-0.12.0 torch-2.6.0 torch-complex-0.4.4 torchaudio-2.6.0 torchmetrics-1.5.0 tqdm-4.67.1 transformers-4.48.3 triton-3.2.0 typeguard-4.4.1 typer-0.15.1 typing-extensions-4.12.2 tzdata-2025.1 umap-learn-0.5.7 uvicorn-0.34.0 wcwidth-0.2.13 websockets-11.0.3 werkzeug-3.1.3 wordfreq-3.1.1 wordsegment-1.3.1 x_transformers-2.0.4 xxhash-3.5.0 yapf-0.43.0 yarl-1.18.3 zipp-3.21.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 20 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libao-common libao4 libid3tag0 libmad0 libopencore-amrnb0 libopencore-amrwb0\n",
            "  libsox-fmt-all libsox-fmt-alsa libsox-fmt-ao libsox-fmt-base libsox-fmt-mp3\n",
            "  libsox-fmt-oss libsox-fmt-pulse libsox3 libwavpack1\n",
            "Suggested packages:\n",
            "  libaudio2 libsndio6.1\n",
            "The following NEW packages will be installed:\n",
            "  libao-common libao4 libid3tag0 libmad0 libopencore-amrnb0 libopencore-amrwb0\n",
            "  libsox-dev libsox-fmt-all libsox-fmt-alsa libsox-fmt-ao libsox-fmt-base\n",
            "  libsox-fmt-mp3 libsox-fmt-oss libsox-fmt-pulse libsox3 libwavpack1\n",
            "0 upgraded, 16 newly installed, 0 to remove and 20 not upgraded.\n",
            "Need to get 1,053 kB of archives.\n",
            "After this operation, 4,061 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libao-common all 1.2.2+20180113-1.1ubuntu3 [6,568 B]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libao4 amd64 1.2.2+20180113-1.1ubuntu3 [35.2 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libid3tag0 amd64 0.15.1b-14 [31.3 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libmad0 amd64 0.15.1b-10ubuntu1 [63.1 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libopencore-amrnb0 amd64 0.1.5-1 [94.8 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libopencore-amrwb0 amd64 0.1.5-1 [49.1 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox3 amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [240 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-alsa amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [11.2 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-ao amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [7,740 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwavpack1 amd64 5.4.0-1build2 [83.7 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-base amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [33.7 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-mp3 amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [17.3 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-oss amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [9,424 B]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-pulse amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [7,732 B]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-all amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [5,016 B]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-dev amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [356 kB]\n",
            "Fetched 1,053 kB in 1s (824 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 16.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libao-common.\n",
            "(Reading database ... 124926 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libao-common_1.2.2+20180113-1.1ubuntu3_all.deb ...\n",
            "Unpacking libao-common (1.2.2+20180113-1.1ubuntu3) ...\n",
            "Selecting previously unselected package libao4:amd64.\n",
            "Preparing to unpack .../01-libao4_1.2.2+20180113-1.1ubuntu3_amd64.deb ...\n",
            "Unpacking libao4:amd64 (1.2.2+20180113-1.1ubuntu3) ...\n",
            "Selecting previously unselected package libid3tag0:amd64.\n",
            "Preparing to unpack .../02-libid3tag0_0.15.1b-14_amd64.deb ...\n",
            "Unpacking libid3tag0:amd64 (0.15.1b-14) ...\n",
            "Selecting previously unselected package libmad0:amd64.\n",
            "Preparing to unpack .../03-libmad0_0.15.1b-10ubuntu1_amd64.deb ...\n",
            "Unpacking libmad0:amd64 (0.15.1b-10ubuntu1) ...\n",
            "Selecting previously unselected package libopencore-amrnb0:amd64.\n",
            "Preparing to unpack .../04-libopencore-amrnb0_0.1.5-1_amd64.deb ...\n",
            "Unpacking libopencore-amrnb0:amd64 (0.1.5-1) ...\n",
            "Selecting previously unselected package libopencore-amrwb0:amd64.\n",
            "Preparing to unpack .../05-libopencore-amrwb0_0.1.5-1_amd64.deb ...\n",
            "Unpacking libopencore-amrwb0:amd64 (0.1.5-1) ...\n",
            "Selecting previously unselected package libsox3:amd64.\n",
            "Preparing to unpack .../06-libsox3_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-alsa:amd64.\n",
            "Preparing to unpack .../07-libsox-fmt-alsa_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-alsa:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-ao:amd64.\n",
            "Preparing to unpack .../08-libsox-fmt-ao_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-ao:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libwavpack1:amd64.\n",
            "Preparing to unpack .../09-libwavpack1_5.4.0-1build2_amd64.deb ...\n",
            "Unpacking libwavpack1:amd64 (5.4.0-1build2) ...\n",
            "Selecting previously unselected package libsox-fmt-base:amd64.\n",
            "Preparing to unpack .../10-libsox-fmt-base_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-base:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-mp3:amd64.\n",
            "Preparing to unpack .../11-libsox-fmt-mp3_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-mp3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-oss:amd64.\n",
            "Preparing to unpack .../12-libsox-fmt-oss_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-oss:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-pulse:amd64.\n",
            "Preparing to unpack .../13-libsox-fmt-pulse_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-pulse:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-all:amd64.\n",
            "Preparing to unpack .../14-libsox-fmt-all_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-all:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-dev:amd64.\n",
            "Preparing to unpack .../15-libsox-dev_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-dev:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox-fmt-oss:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libao-common (1.2.2+20180113-1.1ubuntu3) ...\n",
            "Setting up libid3tag0:amd64 (0.15.1b-14) ...\n",
            "Setting up libopencore-amrwb0:amd64 (0.1.5-1) ...\n",
            "Setting up libsox-fmt-alsa:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libao4:amd64 (1.2.2+20180113-1.1ubuntu3) ...\n",
            "Setting up libmad0:amd64 (0.15.1b-10ubuntu1) ...\n",
            "Setting up libwavpack1:amd64 (5.4.0-1build2) ...\n",
            "Setting up libopencore-amrnb0:amd64 (0.1.5-1) ...\n",
            "Setting up libsox-fmt-base:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox-fmt-ao:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox-fmt-mp3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox-fmt-pulse:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox-fmt-all:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox-dev:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libgettextpo.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libasprintf.so.0 is not a symbolic link\n",
            "\n",
            "Collecting LangSegment\n",
            "  Downloading LangSegment-0.3.5-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.9/site-packages (from LangSegment) (1.23.4)\n",
            "Collecting py3langid>=0.2.2 (from LangSegment)\n",
            "  Downloading py3langid-0.3.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting numpy>=1.19.5 (from LangSegment)\n",
            "  Using cached numpy-2.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Downloading LangSegment-0.3.5-py3-none-any.whl (28 kB)\n",
            "Downloading py3langid-0.3.0-py3-none-any.whl (746 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m746.1/746.1 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached numpy-2.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
            "Installing collected packages: numpy, py3langid, LangSegment\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.4\n",
            "    Uninstalling numpy-1.23.4:\n",
            "      Successfully uninstalled numpy-1.23.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gradio 4.24.0 requires numpy~=1.0, but you have numpy 2.0.2 which is incompatible.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 2.0.2 which is incompatible.\n",
            "torchmetrics 1.5.0 requires numpy<2.0,>1.20.0, but you have numpy 2.0.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed LangSegment-0.3.5 numpy-2.0.2 py3langid-0.3.0\n",
            "Collecting numpy==1.23.4\n",
            "  Using cached numpy-1.23.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Using cached numpy-1.23.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "py3langid 0.3.0 requires numpy>=2.0.0; python_version >= \"3.9\", but you have numpy 1.23.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_rus.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker_tab to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker_tab.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger_tab to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/maxent_treebank_pos_tagger_tab.zip.\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package tagsets_json to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets_json.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ipykernel\n",
            "  Downloading ipykernel-6.29.5-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting comm>=0.1.1 (from ipykernel)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting debugpy>=1.6.5 (from ipykernel)\n",
            "  Downloading debugpy-1.8.12-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting ipython>=7.23.1 (from ipykernel)\n",
            "  Downloading ipython-8.18.1-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting jupyter-client>=6.1.12 (from ipykernel)\n",
            "  Downloading jupyter_client-8.6.3-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting jupyter-core!=5.0.*,>=4.12 (from ipykernel)\n",
            "  Downloading jupyter_core-5.7.2-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting matplotlib-inline>=0.1 (from ipykernel)\n",
            "  Downloading matplotlib_inline-0.1.7-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting nest-asyncio (from ipykernel)\n",
            "  Downloading nest_asyncio-1.6.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/site-packages (from ipykernel) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/site-packages (from ipykernel) (7.0.0)\n",
            "Collecting pyzmq>=24 (from ipykernel)\n",
            "  Downloading pyzmq-26.2.1-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.2 kB)\n",
            "Collecting tornado>=6.1 (from ipykernel)\n",
            "  Downloading tornado-6.4.2-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Collecting traitlets>=5.4.0 (from ipykernel)\n",
            "  Downloading traitlets-5.14.3-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (5.1.1)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting prompt-toolkit<3.1.0,>=3.0.41 (from ipython>=7.23.1->ipykernel)\n",
            "  Downloading prompt_toolkit-3.0.50-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (2.19.1)\n",
            "Collecting stack-data (from ipython>=7.23.1->ipykernel)\n",
            "  Downloading stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (4.12.2)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (1.2.2)\n",
            "Collecting pexpect>4.3 (from ipython>=7.23.1->ipykernel)\n",
            "  Downloading pexpect-4.9.0-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.3 in /usr/local/lib/python3.9/site-packages (from jupyter-client>=6.1.12->ipykernel) (8.6.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.9/site-packages (from jupyter-client>=6.1.12->ipykernel) (2.9.0.post0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.9/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (3.10.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.9/site-packages (from importlib-metadata>=4.8.3->jupyter-client>=6.1.12->ipykernel) (3.21.0)\n",
            "Collecting parso<0.9.0,>=0.8.4 (from jedi>=0.16->ipython>=7.23.1->ipykernel)\n",
            "  Downloading parso-0.8.4-py2.py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting ptyprocess>=0.5 (from pexpect>4.3->ipython>=7.23.1->ipykernel)\n",
            "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel) (1.17.0)\n",
            "Collecting executing>=1.2.0 (from stack-data->ipython>=7.23.1->ipykernel)\n",
            "  Downloading executing-2.2.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting asttokens>=2.1.0 (from stack-data->ipython>=7.23.1->ipykernel)\n",
            "  Downloading asttokens-3.0.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting pure-eval (from stack-data->ipython>=7.23.1->ipykernel)\n",
            "  Downloading pure_eval-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Downloading ipykernel-6.29.5-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Downloading debugpy-1.8.12-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipython-8.18.1-py3-none-any.whl (808 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m808.2/808.2 kB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_client-8.6.3-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_core-5.7.2-py3-none-any.whl (28 kB)\n",
            "Downloading matplotlib_inline-0.1.7-py3-none-any.whl (9.9 kB)\n",
            "Downloading pyzmq-26.2.1-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (867 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m867.5/867.5 kB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tornado-6.4.2-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (437 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m437.2/437.2 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading traitlets-5.14.3-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pexpect-4.9.0-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prompt_toolkit-3.0.50-py3-none-any.whl (387 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m387.8/387.8 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
            "Downloading asttokens-3.0.0-py3-none-any.whl (26 kB)\n",
            "Downloading executing-2.2.0-py2.py3-none-any.whl (26 kB)\n",
            "Downloading parso-0.8.4-py2.py3-none-any.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.7/103.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
            "Downloading pure_eval-0.2.3-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pure-eval, ptyprocess, traitlets, tornado, pyzmq, prompt-toolkit, pexpect, parso, nest-asyncio, executing, debugpy, asttokens, stack-data, matplotlib-inline, jupyter-core, jedi, comm, jupyter-client, ipython, ipykernel\n",
            "Successfully installed asttokens-3.0.0 comm-0.2.2 debugpy-1.8.12 executing-2.2.0 ipykernel-6.29.5 ipython-8.18.1 jedi-0.19.2 jupyter-client-8.6.3 jupyter-core-5.7.2 matplotlib-inline-0.1.7 nest-asyncio-1.6.0 parso-0.8.4 pexpect-4.9.0 prompt-toolkit-3.0.50 ptyprocess-0.7.0 pure-eval-0.2.3 pyzmq-26.2.1 stack-data-0.6.3 tornado-6.4.2 traitlets-5.14.3\n",
            "/content/GPT-SoVITS-v3\n",
            "Running on local URL:  http://127.0.0.1:7860\n",
            "Running on public URL: https://d5fa5a3fe33f907ffd.gradio.live\n",
            "\"/usr/local/bin/python\" tools/slice_audio.py \"jay_speech.wav\" \"output/slicer_opt\" -34 4000 300 10 500 0.9 0.25 0 1\n",
            "执行完毕，请检查输出文件\n",
            "\"/usr/local/bin/python\" tools/asr/funasr_asr.py -i \"output/slicer_opt\" -o \"output/asr_opt\" -s large -l zh -p float32\n",
            "ckpt: tools/asr/models/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch/model.pt\n",
            "ckpt: tools/asr/models/speech_fsmn_vad_zh-cn-16k-common-pytorch/model.pt\n",
            "ckpt: tools/asr/models/punc_ct-transformer_zh-cn-common-vocab272727-pytorch/model.pt\n",
            "FunASR 模型加载完成: ZH\n",
            "  0% 0/1 [00:00<?, ?it/s]\n",
            "jay_speech.wav_0000000000_0000155520.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  1.51it/s]\u001b[A\n",
            "{'load_data': '0.238', 'extract_feat': '0.107', 'forward': '0.660', 'batch_size': '1', 'rtf': '0.137'}, : 100% 1/1 [00:00<00:00,  1.51it/s]\u001b[A\n",
            "rtf_avg: 0.137: 100% 1/1 [00:00<00:00,  1.51it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A/usr/local/lib/python3.9/site-packages/funasr/models/paraformer/model.py:249: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(False):\n",
            "/usr/local/lib/python3.9/site-packages/funasr/models/paraformer/cif_predictor.py:212: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(False):\n",
            "\n",
            "\n",
            "100% 1/1 [00:01<00:00,  1.50s/it]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.008', 'forward': '1.504', 'batch_size': '1', 'rtf': '0.310'}, : 100% 1/1 [00:01<00:00,  1.50s/it]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.310: 100% 1/1 [00:01<00:00,  1.51s/it]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.054', 'batch_size': '1', 'rtf': '-0.054'}, : 100% 1/1 [00:00<00:00, 18.33it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.054: 100% 1/1 [00:00<00:00, 18.22it/s]\n",
            "\n",
            "100% 1/1 [00:01<00:00,  1.58s/it]\u001b[A\n",
            "rtf_avg: 0.323, time_speech:  4.850, time_escape: 1.565: 100% 1/1 [00:01<00:00,  1.58s/it]\n",
            "100% 1/1 [00:02<00:00,  2.24s/it]\n",
            "ASR 任务完成->标注文件路径: /content/GPT-SoVITS-v3/output/asr_opt/slicer_opt.list\n",
            "\n",
            "\"/usr/local/bin/python\" GPT_SoVITS/prepare_datasets/1-get-text.py\n",
            "\"/usr/local/bin/python\" GPT_SoVITS/prepare_datasets/1-get-text.py\n",
            "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
            "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
            "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
            "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
            "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
            "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
            "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
            "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
            "jay_speech.wav_0000000000_0000155520.wav\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GPT-SoVITS-v3/webui.py\", line 683, in open1abc\n",
            "    with open(txt_path, \"r\",encoding=\"utf8\") as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'logs/jay/2-name2text-0.txt'\n",
            "\"/usr/local/bin/python\" tools/slice_audio.py \"jay_speech.wav\" \"output/slicer_opt\" -34 4000 300 10 500 0.9 0.25 0 1\n",
            "执行完毕，请检查输出文件\n",
            "\"/usr/local/bin/python\" tools/asr/funasr_asr.py -i \"output/slicer_opt\" -o \"output/asr_opt\" -s large -l zh -p float32\n",
            "ckpt: tools/asr/models/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch/model.pt\n",
            "ckpt: tools/asr/models/speech_fsmn_vad_zh-cn-16k-common-pytorch/model.pt\n",
            "ckpt: tools/asr/models/punc_ct-transformer_zh-cn-common-vocab272727-pytorch/model.pt\n",
            "FunASR 模型加载完成: ZH\n",
            "  0% 0/13 [00:00<?, ?it/s]\n",
            ".ipynb_checkpoints\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[ATraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/site-packages/funasr/utils/load_utils.py\", line 93, in load_audio_text_image_video\n",
            "    data_or_path_or_list, audio_fs = torchaudio.load(data_or_path_or_list)\n",
            "  File \"/usr/local/lib/python3.9/site-packages/torchaudio/_backend/utils.py\", line 205, in load\n",
            "    return backend.load(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size)\n",
            "  File \"/usr/local/lib/python3.9/site-packages/torchaudio/_backend/ffmpeg.py\", line 297, in load\n",
            "    return load_audio(uri, frame_offset, num_frames, normalize, channels_first, format)\n",
            "  File \"/usr/local/lib/python3.9/site-packages/torchaudio/_backend/ffmpeg.py\", line 88, in load_audio\n",
            "    s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "  File \"/usr/local/lib/python3.9/site-packages/torio/io/_streaming_media_decoder.py\", line 526, in __init__\n",
            "    self._be = ffmpeg_ext.StreamingMediaDecoder(os.path.normpath(src), format, option)\n",
            "RuntimeError: Failed to open the input \"output/slicer_opt/.ipynb_checkpoints\" (Is a directory).\n",
            "Exception raised from get_input_format_context at /__w/audio/audio/pytorch/audio/src/libtorio/ffmpeg/stream_reader/stream_reader.cpp:42 (most recent call first):\n",
            "frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x792fc796c1b6 in /usr/local/lib/python3.9/site-packages/torch/lib/libc10.so)\n",
            "frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x792fc7915a76 in /usr/local/lib/python3.9/site-packages/torch/lib/libc10.so)\n",
            "frame #2: <unknown function> + 0x42034 (0x792ee3cb5034 in /usr/local/lib/python3.9/site-packages/torio/lib/libtorio_ffmpeg4.so)\n",
            "frame #3: torio::io::StreamingMediaDecoder::StreamingMediaDecoder(std::string const&, std::optional<std::string> const&, std::optional<std::map<std::string, std::string, std::less<std::string>, std::allocator<std::pair<std::string const, std::string> > > > const&) + 0x14 (0x792ee3cb7a34 in /usr/local/lib/python3.9/site-packages/torio/lib/libtorio_ffmpeg4.so)\n",
            "frame #4: <unknown function> + 0x3bb7e (0x792eccafeb7e in /usr/local/lib/python3.9/site-packages/torio/lib/_torio_ffmpeg4.so)\n",
            "frame #5: <unknown function> + 0x32b5e (0x792eccaf5b5e in /usr/local/lib/python3.9/site-packages/torio/lib/_torio_ffmpeg4.so)\n",
            "frame #6: /usr/local/bin/python() [0x507387]\n",
            "frame #7: _PyObject_MakeTpCall + 0x2ec (0x4f073c in /usr/local/bin/python)\n",
            "frame #8: /usr/local/bin/python() [0x505313]\n",
            "frame #9: /usr/local/bin/python() [0x502a80]\n",
            "frame #10: /usr/local/bin/python() [0x4f0bea]\n",
            "frame #11: <unknown function> + 0xf7bb (0x792ee3d3a7bb in /usr/local/lib/python3.9/site-packages/torchaudio/lib/_torchaudio.so)\n",
            "frame #12: _PyObject_MakeTpCall + 0x2ec (0x4f073c in /usr/local/bin/python)\n",
            "frame #13: _PyEval_EvalFrameDefault + 0x5263 (0x4ecc93 in /usr/local/bin/python)\n",
            "frame #14: /usr/local/bin/python() [0x4e6b2a]\n",
            "frame #15: _PyObject_FastCallDictTstate + 0x13e (0x4effae in /usr/local/bin/python)\n",
            "frame #16: /usr/local/bin/python() [0x5027bf]\n",
            "frame #17: _PyObject_MakeTpCall + 0x303 (0x4f0753 in /usr/local/bin/python)\n",
            "frame #18: _PyEval_EvalFrameDefault + 0x5263 (0x4ecc93 in /usr/local/bin/python)\n",
            "frame #19: /usr/local/bin/python() [0x4e6b2a]\n",
            "frame #20: _PyFunction_Vectorcall + 0xd4 (0x4f7e54 in /usr/local/bin/python)\n",
            "frame #21: _PyEval_EvalFrameDefault + 0x3c7 (0x4e7df7 in /usr/local/bin/python)\n",
            "frame #22: /usr/local/bin/python() [0x4e6b2a]\n",
            "frame #23: _PyFunction_Vectorcall + 0xd4 (0x4f7e54 in /usr/local/bin/python)\n",
            "frame #24: _PyEval_EvalFrameDefault + 0x4d34 (0x4ec764 in /usr/local/bin/python)\n",
            "frame #25: /usr/local/bin/python() [0x4e6b2a]\n",
            "frame #26: _PyFunction_Vectorcall + 0xd4 (0x4f7e54 in /usr/local/bin/python)\n",
            "frame #27: _PyEval_EvalFrameDefault + 0x4d34 (0x4ec764 in /usr/local/bin/python)\n",
            "frame #28: /usr/local/bin/python() [0x4e6b2a]\n",
            "frame #29: _PyFunction_Vectorcall + 0xd4 (0x4f7e54 in /usr/local/bin/python)\n",
            "frame #30: PyObject_Call + 0xb4 (0x5057d4 in /usr/local/bin/python)\n",
            "frame #31: _PyEval_EvalFrameDefault + 0x3e14 (0x4eb844 in /usr/local/bin/python)\n",
            "frame #32: /usr/local/bin/python() [0x4e6b2a]\n",
            "frame #33: _PyFunction_Vectorcall + 0xd4 (0x4f7e54 in /usr/local/bin/python)\n",
            "frame #34: _PyEval_EvalFrameDefault + 0x3c7 (0x4e7df7 in /usr/local/bin/python)\n",
            "frame #35: /usr/local/bin/python() [0x4e6b2a]\n",
            "frame #36: _PyFunction_Vectorcall + 0xd4 (0x4f7e54 in /usr/local/bin/python)\n",
            "frame #37: _PyEval_EvalFrameDefault + 0x1231 (0x4e8c61 in /usr/local/bin/python)\n",
            "frame #38: /usr/local/bin/python() [0x4e6b2a]\n",
            "frame #39: /usr/local/bin/python() [0x50508d]\n",
            "frame #40: PyObject_Call + 0xb4 (0x5057d4 in /usr/local/bin/python)\n",
            "frame #41: _PyEval_EvalFrameDefault + 0x3e14 (0x4eb844 in /usr/local/bin/python)\n",
            "frame #42: /usr/local/bin/python() [0x4e6b2a]\n",
            "frame #43: /usr/local/bin/python() [0x50508d]\n",
            "frame #44: PyObject_Call + 0xb4 (0x5057d4 in /usr/local/bin/python)\n",
            "frame #45: _PyEval_EvalFrameDefault + 0x3e14 (0x4eb844 in /usr/local/bin/python)\n",
            "frame #46: /usr/local/bin/python() [0x4e6b2a]\n",
            "frame #47: /usr/local/bin/python() [0x50508d]\n",
            "frame #48: PyObject_Call + 0xb4 (0x5057d4 in /usr/local/bin/python)\n",
            "frame #49: _PyEval_EvalFrameDefault + 0x3e14 (0x4eb844 in /usr/local/bin/python)\n",
            "frame #50: /usr/local/bin/python() [0x4e6b2a]\n",
            "frame #51: /usr/local/bin/python() [0x50508d]\n",
            "frame #52: _PyEval_EvalFrameDefault + 0x1231 (0x4e8c61 in /usr/local/bin/python)\n",
            "frame #53: /usr/local/bin/python() [0x4e6b2a]\n",
            "frame #54: _PyFunction_Vectorcall + 0xd4 (0x4f7e54 in /usr/local/bin/python)\n",
            "frame #55: _PyEval_EvalFrameDefault + 0x1231 (0x4e8c61 in /usr/local/bin/python)\n",
            "frame #56: /usr/local/bin/python() [0x4e6b2a]\n",
            "frame #57: _PyEval_EvalCodeWithName + 0x47 (0x4e67b7 in /usr/local/bin/python)\n",
            "frame #58: PyEval_EvalCodeEx + 0x39 (0x4e6769 in /usr/local/bin/python)\n",
            "frame #59: PyEval_EvalCode + 0x1b (0x59466b in /usr/local/bin/python)\n",
            "frame #60: /usr/local/bin/python() [0x5c1dc7]\n",
            "frame #61: /usr/local/bin/python() [0x5bddd0]\n",
            "frame #62: /usr/local/bin/python() [0x45674e]\n",
            "\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/site-packages/funasr/utils/load_utils.py\", line 213, in _load_audio_ffmpeg\n",
            "    out = run(cmd, capture_output=True, check=True).stdout\n",
            "  File \"/usr/local/lib/python3.9/subprocess.py\", line 528, in run\n",
            "    raise CalledProcessError(retcode, process.args,\n",
            "subprocess.CalledProcessError: Command '['ffmpeg', '-nostdin', '-threads', '0', '-i', 'output/slicer_opt/.ipynb_checkpoints', '-f', 's16le', '-ac', '1', '-acodec', 'pcm_s16le', '-ar', '16000', '-']' returned non-zero exit status 235.\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GPT-SoVITS-v3/tools/asr/funasr_asr.py\", line 73, in execute_asr\n",
            "    text = model.generate(input=file_path)[0][\"text\"]\n",
            "  File \"/usr/local/lib/python3.9/site-packages/funasr/auto/auto_model.py\", line 248, in generate\n",
            "    return self.inference_with_vad(input, input_len=input_len, **cfg)\n",
            "  File \"/usr/local/lib/python3.9/site-packages/funasr/auto/auto_model.py\", line 319, in inference_with_vad\n",
            "    res = self.inference(\n",
            "  File \"/usr/local/lib/python3.9/site-packages/funasr/auto/auto_model.py\", line 285, in inference\n",
            "    res = model.inference(**batch, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/site-packages/funasr/models/fsmn_vad_streaming/model.py\", line 676, in inference\n",
            "    audio_sample_list = load_audio_text_image_video(\n",
            "  File \"/usr/local/lib/python3.9/site-packages/funasr/utils/load_utils.py\", line 72, in load_audio_text_image_video\n",
            "    return [\n",
            "  File \"/usr/local/lib/python3.9/site-packages/funasr/utils/load_utils.py\", line 73, in <listcomp>\n",
            "    load_audio_text_image_video(\n",
            "  File \"/usr/local/lib/python3.9/site-packages/funasr/utils/load_utils.py\", line 97, in load_audio_text_image_video\n",
            "    data_or_path_or_list = _load_audio_ffmpeg(data_or_path_or_list, sr=fs)\n",
            "  File \"/usr/local/lib/python3.9/site-packages/funasr/utils/load_utils.py\", line 215, in _load_audio_ffmpeg\n",
            "    raise RuntimeError(f\"Failed to load audio: {e.stderr.decode()}\") from e\n",
            "RuntimeError: Failed to load audio: ffmpeg version 7.0.1 Copyright (c) 2000-2024 the FFmpeg developers\n",
            "  built with gcc 12.3.0 (conda-forge gcc 12.3.0-7)\n",
            "  configuration: --prefix=/usr/local --cc=/home/conda/feedstock_root/build_artifacts/ffmpeg_1716729489913/_build_env/bin/x86_64-conda-linux-gnu-cc --cxx=/home/conda/feedstock_root/build_artifacts/ffmpeg_1716729489913/_build_env/bin/x86_64-conda-linux-gnu-c++ --nm=/home/conda/feedstock_root/build_artifacts/ffmpeg_1716729489913/_build_env/bin/x86_64-conda-linux-gnu-nm --ar=/home/conda/feedstock_root/build_artifacts/ffmpeg_1716729489913/_build_env/bin/x86_64-conda-linux-gnu-ar --disable-doc --disable-openssl --enable-demuxer=dash --enable-hardcoded-tables --enable-libfreetype --enable-libharfbuzz --enable-libfontconfig --enable-libopenh264 --enable-libdav1d --enable-gnutls --enable-libmp3lame --enable-libvpx --enable-libass --enable-pthreads --enable-vaapi --enable-libopenvino --enable-gpl --enable-libx264 --enable-libx265 --enable-libaom --enable-libsvtav1 --enable-libxml2 --enable-pic --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libopus --pkg-config=/home/conda/feedstock_root/build_artifacts/ffmpeg_1716729489913/_build_env/bin/pkg-config\n",
            "  libavutil      59.  8.100 / 59.  8.100\n",
            "  libavcodec     61.  3.100 / 61.  3.100\n",
            "  libavformat    61.  1.100 / 61.  1.100\n",
            "  libavdevice    61.  1.100 / 61.  1.100\n",
            "  libavfilter    10.  1.100 / 10.  1.100\n",
            "  libswscale      8.  1.100 /  8.  1.100\n",
            "  libswresample   5.  1.100 /  5.  1.100\n",
            "  libpostproc    58.  1.100 / 58.  1.100\n",
            "[in#0 @ 0x5868b4bd3280] Error opening input: Is a directory\n",
            "Error opening input file output/slicer_opt/.ipynb_checkpoints.\n",
            "Error opening input files: Is a directory\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\n",
            "  8% 1/13 [00:00<00:01,  8.08it/s]\n",
            "jay_speech.wav_0000000000_0000325120.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  1.26it/s]\u001b[A\n",
            "{'load_data': '0.272', 'extract_feat': '0.121', 'forward': '0.793', 'batch_size': '1', 'rtf': '0.078'}, : 100% 1/1 [00:00<00:00,  1.26it/s]\u001b[A\n",
            "rtf_avg: 0.078: 100% 1/1 [00:00<00:00,  1.26it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A/usr/local/lib/python3.9/site-packages/funasr/models/paraformer/model.py:249: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(False):\n",
            "/usr/local/lib/python3.9/site-packages/funasr/models/paraformer/cif_predictor.py:212: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(False):\n",
            "\n",
            "\n",
            "100% 1/1 [00:01<00:00,  1.32s/it]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.016', 'forward': '1.323', 'batch_size': '1', 'rtf': '0.130'}, : 100% 1/1 [00:01<00:00,  1.32s/it]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.130: 100% 1/1 [00:01<00:00,  1.32s/it]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.066', 'batch_size': '1', 'rtf': '-0.066'}, : 100% 1/1 [00:00<00:00, 15.23it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.066: 100% 1/1 [00:00<00:00, 15.17it/s]\n",
            "\n",
            "100% 1/1 [00:01<00:00,  1.41s/it]\u001b[A\n",
            "rtf_avg: 0.137, time_speech:  10.160, time_escape: 1.395: 100% 1/1 [00:01<00:00,  1.41s/it]\n",
            " 15% 2/13 [00:02<00:14,  1.35s/it]\n",
            "jay_speech.wav_0000325120_0000449920.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "{'load_data': '0.015', 'extract_feat': '0.010', 'forward': '0.059', 'batch_size': '1', 'rtf': '0.015'}, : 100% 1/1 [00:00<00:00, 16.91it/s]\u001b[A\n",
            "rtf_avg: 0.015: 100% 1/1 [00:00<00:00, 16.79it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100% 1/1 [00:00<00:00,  7.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.006', 'forward': '0.142', 'batch_size': '1', 'rtf': '0.036'}, : 100% 1/1 [00:00<00:00,  7.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.036: 100% 1/1 [00:00<00:00,  7.01it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.013', 'batch_size': '1', 'rtf': '-0.013'}, : 100% 1/1 [00:00<00:00, 76.53it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.013: 100% 1/1 [00:00<00:00, 74.22it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  5.77it/s]\u001b[A\n",
            "rtf_avg: 0.041, time_speech:  3.900, time_escape: 0.161: 100% 1/1 [00:00<00:00,  5.76it/s]\n",
            " 23% 3/13 [00:02<00:08,  1.19it/s]\n",
            "jay_speech.wav_0000449920_0000595520.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "{'load_data': '0.014', 'extract_feat': '0.009', 'forward': '0.065', 'batch_size': '1', 'rtf': '0.014'}, : 100% 1/1 [00:00<00:00, 15.35it/s]\u001b[A\n",
            "rtf_avg: 0.014: 100% 1/1 [00:00<00:00, 15.29it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100% 1/1 [00:00<00:00,  9.68it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.007', 'forward': '0.103', 'batch_size': '1', 'rtf': '0.023'}, : 100% 1/1 [00:00<00:00,  9.68it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.023: 100% 1/1 [00:00<00:00,  9.53it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.013', 'batch_size': '1', 'rtf': '-0.013'}, : 100% 1/1 [00:00<00:00, 77.85it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.013: 100% 1/1 [00:00<00:00, 76.31it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  7.31it/s]\u001b[A\n",
            "rtf_avg: 0.027, time_speech:  4.550, time_escape: 0.123: 100% 1/1 [00:00<00:00,  7.30it/s]\n",
            " 31% 4/13 [00:02<00:05,  1.70it/s]\n",
            "jay_speech.wav_0000595520_0000722880.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "{'load_data': '0.014', 'extract_feat': '0.008', 'forward': '0.057', 'batch_size': '1', 'rtf': '0.014'}, : 100% 1/1 [00:00<00:00, 17.53it/s]\u001b[A\n",
            "rtf_avg: 0.014: 100% 1/1 [00:00<00:00, 17.39it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100% 1/1 [00:00<00:00,  8.92it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.006', 'forward': '0.112', 'batch_size': '1', 'rtf': '0.028'}, : 100% 1/1 [00:00<00:00,  8.92it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.028: 100% 1/1 [00:00<00:00,  8.89it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.007', 'batch_size': '1', 'rtf': '-0.007'}, : 100% 1/1 [00:00<00:00, 151.19it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.007: 100% 1/1 [00:00<00:00, 141.00it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  6.94it/s]\u001b[A\n",
            "rtf_avg: 0.032, time_speech:  3.980, time_escape: 0.126: 100% 1/1 [00:00<00:00,  6.93it/s]\n",
            " 38% 5/13 [00:02<00:03,  2.22it/s]\n",
            "jay_speech.wav_0000722880_0001060480.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  7.48it/s]\u001b[A\n",
            "{'load_data': '0.026', 'extract_feat': '0.019', 'forward': '0.134', 'batch_size': '1', 'rtf': '0.013'}, : 100% 1/1 [00:00<00:00,  7.48it/s]\u001b[A\n",
            "rtf_avg: 0.013: 100% 1/1 [00:00<00:00,  7.42it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100% 1/1 [00:00<00:00,  6.89it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.021', 'forward': '0.145', 'batch_size': '1', 'rtf': '0.014'}, : 100% 1/1 [00:00<00:00,  6.89it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.014: 100% 1/1 [00:00<00:00,  6.86it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.020', 'batch_size': '1', 'rtf': '-0.020'}, : 100% 1/1 [00:00<00:00, 49.76it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.020: 100% 1/1 [00:00<00:00, 49.22it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  5.16it/s]\u001b[A\n",
            "rtf_avg: 0.016, time_speech:  10.550, time_escape: 0.174: 100% 1/1 [00:00<00:00,  5.15it/s]\n",
            " 46% 6/13 [00:03<00:02,  2.44it/s]\n",
            "jay_speech.wav_0001060480_0001209920.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "{'load_data': '0.013', 'extract_feat': '0.011', 'forward': '0.065', 'batch_size': '1', 'rtf': '0.014'}, : 100% 1/1 [00:00<00:00, 15.25it/s]\u001b[A\n",
            "rtf_avg: 0.014: 100% 1/1 [00:00<00:00, 15.13it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100% 1/1 [00:00<00:00,  9.60it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.007', 'forward': '0.104', 'batch_size': '1', 'rtf': '0.022'}, : 100% 1/1 [00:00<00:00,  9.60it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.022: 100% 1/1 [00:00<00:00,  9.54it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.013', 'batch_size': '1', 'rtf': '-0.013'}, : 100% 1/1 [00:00<00:00, 78.16it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.013: 100% 1/1 [00:00<00:00, 75.70it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  7.39it/s]\u001b[A\n",
            "rtf_avg: 0.026, time_speech:  4.670, time_escape: 0.123: 100% 1/1 [00:00<00:00,  7.38it/s]\n",
            " 54% 7/13 [00:03<00:02,  2.93it/s]\n",
            "jay_speech.wav_0001209920_0001361600.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "{'load_data': '0.013', 'extract_feat': '0.009', 'forward': '0.068', 'batch_size': '1', 'rtf': '0.014'}, : 100% 1/1 [00:00<00:00, 14.70it/s]\u001b[A\n",
            "rtf_avg: 0.014: 100% 1/1 [00:00<00:00, 14.64it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100% 1/1 [00:00<00:00,  9.63it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.006', 'forward': '0.104', 'batch_size': '1', 'rtf': '0.022'}, : 100% 1/1 [00:00<00:00,  9.63it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.022: 100% 1/1 [00:00<00:00,  9.49it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.007', 'batch_size': '1', 'rtf': '-0.007'}, : 100% 1/1 [00:00<00:00, 139.90it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.007: 100% 1/1 [00:00<00:00, 134.86it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  7.66it/s]\u001b[A\n",
            "rtf_avg: 0.025, time_speech:  4.740, time_escape: 0.118: 100% 1/1 [00:00<00:00,  7.65it/s]\n",
            " 62% 8/13 [00:03<00:01,  3.37it/s]\n",
            "jay_speech.wav_0001361600_0001516800.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "{'load_data': '0.014', 'extract_feat': '0.009', 'forward': '0.076', 'batch_size': '1', 'rtf': '0.016'}, : 100% 1/1 [00:00<00:00, 13.10it/s]\u001b[A\n",
            "rtf_avg: 0.016: 100% 1/1 [00:00<00:00, 13.02it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100% 1/1 [00:00<00:00,  9.40it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.008', 'forward': '0.106', 'batch_size': '1', 'rtf': '0.022'}, : 100% 1/1 [00:00<00:00,  9.40it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.022: 100% 1/1 [00:00<00:00,  9.32it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.013', 'batch_size': '1', 'rtf': '-0.013'}, : 100% 1/1 [00:00<00:00, 75.08it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.013: 100% 1/1 [00:00<00:00, 72.87it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  7.07it/s]\u001b[A\n",
            "rtf_avg: 0.026, time_speech:  4.850, time_escape: 0.127: 100% 1/1 [00:00<00:00,  7.06it/s]\n",
            " 69% 9/13 [00:03<00:01,  3.67it/s]\n",
            "jay_speech.wav_0001516800_0001681600.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "{'load_data': '0.020', 'extract_feat': '0.016', 'forward': '0.088', 'batch_size': '1', 'rtf': '0.017'}, : 100% 1/1 [00:00<00:00, 11.30it/s]\u001b[A\n",
            "rtf_avg: 0.017: 100% 1/1 [00:00<00:00, 11.22it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100% 1/1 [00:00<00:00,  9.21it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.007', 'forward': '0.109', 'batch_size': '1', 'rtf': '0.021'}, : 100% 1/1 [00:00<00:00,  9.21it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.021: 100% 1/1 [00:00<00:00,  9.15it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.013', 'batch_size': '1', 'rtf': '-0.013'}, : 100% 1/1 [00:00<00:00, 76.11it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.013: 100% 1/1 [00:00<00:00, 73.78it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  7.09it/s]\u001b[A\n",
            "rtf_avg: 0.025, time_speech:  5.150, time_escape: 0.128: 100% 1/1 [00:00<00:00,  7.08it/s]\n",
            " 77% 10/13 [00:04<00:00,  3.85it/s]\n",
            "jay_speech.wav_0001681600_0001896640.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "{'load_data': '0.015', 'extract_feat': '0.011', 'forward': '0.082', 'batch_size': '1', 'rtf': '0.012'}, : 100% 1/1 [00:00<00:00, 12.16it/s]\u001b[A\n",
            "rtf_avg: 0.012: 100% 1/1 [00:00<00:00, 12.07it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100% 1/1 [00:00<00:00,  7.29it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.009', 'forward': '0.137', 'batch_size': '1', 'rtf': '0.020'}, : 100% 1/1 [00:00<00:00,  7.29it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.020: 100% 1/1 [00:00<00:00,  7.26it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.014', 'batch_size': '1', 'rtf': '-0.014'}, : 100% 1/1 [00:00<00:00, 71.54it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.014: 100% 1/1 [00:00<00:00, 70.32it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  5.64it/s]\u001b[A\n",
            "rtf_avg: 0.024, time_speech:  6.720, time_escape: 0.160: 100% 1/1 [00:00<00:00,  5.64it/s]\n",
            " 85% 11/13 [00:04<00:00,  3.84it/s]\n",
            "jay_speech.wav_0001896640_0002034560.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "{'load_data': '0.013', 'extract_feat': '0.009', 'forward': '0.059', 'batch_size': '1', 'rtf': '0.014'}, : 100% 1/1 [00:00<00:00, 17.00it/s]\u001b[A\n",
            "rtf_avg: 0.014: 100% 1/1 [00:00<00:00, 16.88it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100% 1/1 [00:00<00:00,  9.18it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.007', 'forward': '0.109', 'batch_size': '1', 'rtf': '0.026'}, : 100% 1/1 [00:00<00:00,  9.18it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.026: 100% 1/1 [00:00<00:00,  9.12it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.006', 'batch_size': '1', 'rtf': '-0.006'}, : 100% 1/1 [00:00<00:00, 151.98it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.006: 100% 1/1 [00:00<00:00, 146.68it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  7.48it/s]\u001b[A\n",
            "rtf_avg: 0.028, time_speech:  4.310, time_escape: 0.121: 100% 1/1 [00:00<00:00,  7.46it/s]\n",
            " 92% 12/13 [00:04<00:00,  4.16it/s]\n",
            "jay_speech.wav_0002034560_0002233280.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "{'load_data': '0.014', 'extract_feat': '0.011', 'forward': '0.078', 'batch_size': '1', 'rtf': '0.013'}, : 100% 1/1 [00:00<00:00, 12.88it/s]\u001b[A\n",
            "rtf_avg: 0.013: 100% 1/1 [00:00<00:00, 12.83it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100% 1/1 [00:00<00:00,  7.64it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.008', 'forward': '0.131', 'batch_size': '1', 'rtf': '0.021'}, : 100% 1/1 [00:00<00:00,  7.64it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.021: 100% 1/1 [00:00<00:00,  7.58it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.044', 'batch_size': '1', 'rtf': '-0.044'}, : 100% 1/1 [00:00<00:00, 22.56it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.044: 100% 1/1 [00:00<00:00, 22.33it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  5.13it/s]\u001b[A\n",
            "rtf_avg: 0.029, time_speech:  6.210, time_escape: 0.181: 100% 1/1 [00:00<00:00,  5.12it/s]\n",
            "100% 13/13 [00:04<00:00,  2.66it/s]\n",
            "ASR 任务完成->标注文件路径: /content/GPT-SoVITS-v3/output/asr_opt/slicer_opt.list\n",
            "\n",
            "\"/usr/local/bin/python\" GPT_SoVITS/prepare_datasets/1-get-text.py\n",
            "\"/usr/local/bin/python\" GPT_SoVITS/prepare_datasets/1-get-text.py\n",
            "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
            "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
            "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
            "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
            "jay_speech.wav_0000000000_0000325120.wav\n",
            "当前使用g2pw进行拼音推理\n",
            "Building prefix dict from the default dictionary ...\n",
            "Dumping model to file cache /content/GPT-SoVITS-v3/TEMP/jieba.cache\n",
            "Loading model cost 0.685 seconds.\n",
            "Prefix dict has been built succesfully.\n",
            "jay_speech.wav_0000449920_0000595520.wav\n",
            "jay_speech.wav_0000722880_0001060480.wav\n",
            "jay_speech.wav_0001209920_0001361600.wav\n",
            "jay_speech.wav_0001516800_0001681600.wav\n",
            "jay_speech.wav_0001896640_0002034560.wav\n",
            "\"/usr/local/bin/python\" GPT_SoVITS/prepare_datasets/2-get-hubert-wav32k.py\n",
            "\"/usr/local/bin/python\" GPT_SoVITS/prepare_datasets/2-get-hubert-wav32k.py\n",
            "\"/usr/local/bin/python\" GPT_SoVITS/prepare_datasets/3-get-semantic.py\n",
            "\"/usr/local/bin/python\" GPT_SoVITS/prepare_datasets/3-get-semantic.py\n",
            "<All keys matched successfully>\n",
            "<All keys matched successfully>\n",
            "\"/usr/local/bin/python\" GPT_SoVITS/s2_train_v3.py --config \"/content/GPT-SoVITS-v3/TEMP/tmp_s2.json\"\n",
            "\"/usr/local/bin/python\" GPT_SoVITS/s1_train.py --config_file \"/content/GPT-SoVITS-v3/TEMP/tmp_s1.yaml\" \n",
            "Seed set to 1234\n",
            "Using 16bit Automatic Mixed Precision (AMP)\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "<All keys matched successfully>\n",
            "ckpt_path: None\n",
            "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "distributed_backend=nccl\n",
            "All distributed processes registered. Starting with 1 processes\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "semantic_data_len: 12\n",
            "phoneme_data_len: 6\n",
            "                                   item_name                                     semantic_audio\n",
            "0   jay_speech.wav_0000000000_0000325120.wav  520 53 53 875 545 600 798 648 905 888 645 300 ...\n",
            "1   jay_speech.wav_0000449920_0000595520.wav  520 274 650 138 36 408 767 331 613 0 449 830 1...\n",
            "2   jay_speech.wav_0000722880_0001060480.wav  520 234 41 420 681 966 951 865 690 846 551 189...\n",
            "3   jay_speech.wav_0001209920_0001361600.wav  171 124 860 820 685 666 361 361 740 395 97 74 ...\n",
            "4   jay_speech.wav_0001516800_0001681600.wav  520 271 53 53 234 98 548 423 60 847 147 166 94...\n",
            "5   jay_speech.wav_0001896640_0002034560.wav  520 53 105 105 105 53 271 41 576 904 200 6 662...\n",
            "6   jay_speech.wav_0000325120_0000449920.wav  520 505 190 590 761 176 628 103 879 907 388 46...\n",
            "7   jay_speech.wav_0000595520_0000722880.wav  54 707 18 906 632 229 596 190 148 759 671 495 ...\n",
            "8   jay_speech.wav_0001060480_0001209920.wav  54 59 1006 680 1023 947 493 387 550 161 705 97...\n",
            "9   jay_speech.wav_0001361600_0001516800.wav  1012 576 284 137 495 1003 253 485 253 203 672 ...\n",
            "10  jay_speech.wav_0001681600_0001896640.wav  54 714 560 87 792 39 265 305 891 305 305 92 32...\n",
            "11  jay_speech.wav_0002034560_0002233280.wav  520 234 505 804 700 219 836 31 821 551 306 766...\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GPT-SoVITS-v3/GPT_SoVITS/AR/data/dataset.py\", line 133, in init_batch\n",
            "    phoneme, word2ph, text = self.phoneme_data[item_name]\n",
            "KeyError: 'jay_speech.wav_0000325120_0000449920.wav'\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GPT-SoVITS-v3/GPT_SoVITS/AR/data/dataset.py\", line 133, in init_batch\n",
            "    phoneme, word2ph, text = self.phoneme_data[item_name]\n",
            "KeyError: 'jay_speech.wav_0000595520_0000722880.wav'\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GPT-SoVITS-v3/GPT_SoVITS/AR/data/dataset.py\", line 133, in init_batch\n",
            "    phoneme, word2ph, text = self.phoneme_data[item_name]\n",
            "KeyError: 'jay_speech.wav_0001060480_0001209920.wav'\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GPT-SoVITS-v3/GPT_SoVITS/AR/data/dataset.py\", line 133, in init_batch\n",
            "    phoneme, word2ph, text = self.phoneme_data[item_name]\n",
            "KeyError: 'jay_speech.wav_0001361600_0001516800.wav'\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GPT-SoVITS-v3/GPT_SoVITS/AR/data/dataset.py\", line 133, in init_batch\n",
            "    phoneme, word2ph, text = self.phoneme_data[item_name]\n",
            "KeyError: 'jay_speech.wav_0001681600_0001896640.wav'\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GPT-SoVITS-v3/GPT_SoVITS/AR/data/dataset.py\", line 133, in init_batch\n",
            "    phoneme, word2ph, text = self.phoneme_data[item_name]\n",
            "KeyError: 'jay_speech.wav_0002034560_0002233280.wav'\n",
            "there are 6 semantic datas not in phoneme datas\n",
            "dataset.__len__(): 96\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name  | Type                 | Params | Mode \n",
            "-------------------------------------------------------\n",
            "0 | model | Text2SemanticDecoder | 77.6 M | train\n",
            "-------------------------------------------------------\n",
            "77.6 M    Trainable params\n",
            "0         Non-trainable params\n",
            "77.6 M    Total params\n",
            "310.426   Total estimated model params size (MB)\n",
            "257       Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "Epoch 1:   0% 0/14 [00:00<?, ?it/s, v_num=0, total_loss_step=2.5e+3, lr_step=0.002, top_3_acc_step=0.222, total_loss_epoch=4.89e+3, lr_epoch=0.00375, top_3_acc_epoch=0.219]phoneme_data_len: 6\n",
            "wav_data_len: 96\n",
            "100% 96/96 [00:00<00:00, 41795.02it/s]\n",
            "skipped_phone:  0 , skipped_dur:  0\n",
            "total left:  96\n",
            "Epoch 4:   0% 0/14 [00:00<?, ?it/s, v_num=0, total_loss_step=2.42e+3, lr_step=0.002, top_3_acc_step=0.244, total_loss_epoch=4.88e+3, lr_epoch=0.002, top_3_acc_epoch=0.221]<All keys matched successfully>\n",
            "  0% 0/96 [01:02<?, ?it/s]\n",
            "Epoch 9:   0% 0/14 [00:00<?, ?it/s, v_num=0, total_loss_step=927.0, lr_step=0.002, top_3_acc_step=0.826, total_loss_epoch=2.64e+3, lr_epoch=0.002, top_3_acc_epoch=0.663][rank0]:[W216 00:21:32.040959175 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GPT-SoVITS-v3/GPT_SoVITS/s2_train_v3.py\", line 413, in <module>\n",
            "    main()\n",
            "  File \"/content/GPT-SoVITS-v3/GPT_SoVITS/s2_train_v3.py\", line 57, in main\n",
            "    mp.spawn(\n",
            "  File \"/usr/local/lib/python3.9/site-packages/torch/multiprocessing/spawn.py\", line 340, in spawn\n",
            "    return start_processes(fn, args, nprocs, join, daemon, start_method=\"spawn\")\n",
            "  File \"/usr/local/lib/python3.9/site-packages/torch/multiprocessing/spawn.py\", line 296, in start_processes\n",
            "    while not context.join():\n",
            "  File \"/usr/local/lib/python3.9/site-packages/torch/multiprocessing/spawn.py\", line 215, in join\n",
            "    raise ProcessRaisedException(msg, error_index, failed_process.pid)\n",
            "torch.multiprocessing.spawn.ProcessRaisedException: \n",
            "\n",
            "-- Process 0 terminated with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/site-packages/torch/multiprocessing/spawn.py\", line 90, in _wrap\n",
            "    fn(i, *args)\n",
            "  File \"/content/GPT-SoVITS-v3/GPT_SoVITS/s2_train_v3.py\", line 229, in run\n",
            "    train_and_evaluate(\n",
            "  File \"/content/GPT-SoVITS-v3/GPT_SoVITS/s2_train_v3.py\", line 313, in train_and_evaluate\n",
            "    scaler.step(optim_g)\n",
            "  File \"/usr/local/lib/python3.9/site-packages/torch/amp/grad_scaler.py\", line 457, in step\n",
            "    retval = self._maybe_opt_step(optimizer, optimizer_state, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/site-packages/torch/amp/grad_scaler.py\", line 352, in _maybe_opt_step\n",
            "    retval = optimizer.step(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/site-packages/torch/optim/lr_scheduler.py\", line 140, in wrapper\n",
            "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/site-packages/torch/optim/optimizer.py\", line 493, in wrapper\n",
            "    out = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/site-packages/torch/optim/optimizer.py\", line 91, in _use_grad\n",
            "    ret = func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/site-packages/torch/optim/adamw.py\", line 243, in step\n",
            "    adamw(\n",
            "  File \"/usr/local/lib/python3.9/site-packages/torch/optim/optimizer.py\", line 154, in maybe_fallback\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/site-packages/torch/optim/adamw.py\", line 875, in adamw\n",
            "    func(\n",
            "  File \"/usr/local/lib/python3.9/site-packages/torch/optim/adamw.py\", line 699, in _multi_tensor_adamw\n",
            "    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)\n",
            "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 14.12 MiB is free. Process 137323 has 5.85 GiB memory in use. Process 137945 has 8.87 GiB memory in use. Of the allocated memory 8.38 GiB is allocated by PyTorch, and 26.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "\n",
            "Epoch 14: 100% 14/14 [00:02<00:00,  6.11it/s, v_num=0, total_loss_step=273.0, lr_step=0.002, top_3_acc_step=1.000, total_loss_epoch=295.0, lr_epoch=0.002, top_3_acc_epoch=1.000]`Trainer.fit` stopped: `max_epochs=15` reached.\n",
            "Epoch 14: 100% 14/14 [00:51<00:00,  3.69s/it, v_num=0, total_loss_step=273.0, lr_step=0.002, top_3_acc_step=1.000, total_loss_epoch=295.0, lr_epoch=0.002, top_3_acc_epoch=1.000]\n",
            "\"/usr/local/bin/python\" GPT_SoVITS/s2_train_v3.py --config \"/content/GPT-SoVITS-v3/TEMP/tmp_s2.json\"\n",
            "phoneme_data_len: 6\n",
            "wav_data_len: 96\n",
            "100% 96/96 [00:00<00:00, 79278.04it/s]\n",
            "skipped_phone:  0 , skipped_dur:  0\n",
            "total left:  96\n",
            "<All keys matched successfully>\n",
            "100% 96/96 [01:38<00:00,  1.03s/it]\n",
            "100% 96/96 [01:00<00:00,  1.59it/s]\n",
            "[rank0]:[W216 00:31:29.136135203 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n",
            "\"/usr/local/bin/python\" GPT_SoVITS/inference_webui.py \"zh_CN\"\n",
            "loading sovits_v3 <All keys matched successfully>\n",
            "Running on local URL:  http://0.0.0.0:8000\n",
            "Running on public URL: https://2416fc128bd9c6d7e1.gradio.live\n",
            "实际输入的参考文本: 尊师重道，那时候他很希望我可以考上音乐系，然后读大学。这样对，让我大概考了两次吧，可能我不是读书的料，而且我又很爱打球。\n",
            "实际输入的目标文本: 尊师重道，那时候他很希望我可以考上音乐系，然后读大学。这样对，让我大概考了两次吧，可能我不是读书的料，而且我又很爱打球。\n",
            "实际输入的目标文本(切句后): 尊师重道，那时候他很希望我可以考上音乐系，然后读大学。这样对，让我大概考了两次吧，可能我不是读书的料，而且我又很爱打球。\n",
            "当前使用g2pw进行拼音推理\n",
            "Building prefix dict from the default dictionary ...\n",
            "DEBUG:jieba_fast:Building prefix dict from the default dictionary ...\n",
            "Loading model from cache /content/GPT-SoVITS-v3/TEMP/jieba.cache\n",
            "DEBUG:jieba_fast:Loading model from cache /content/GPT-SoVITS-v3/TEMP/jieba.cache\n",
            "Loading model cost 0.776 seconds.\n",
            "DEBUG:jieba_fast:Loading model cost 0.776 seconds.\n",
            "Prefix dict has been built succesfully.\n",
            "DEBUG:jieba_fast:Prefix dict has been built succesfully.\n",
            "实际输入的目标文本(每句): 尊师重道，那时候他很希望我可以考上音乐系，然后读大学。这样对，让我大概考了两次吧，可能我不是读书的料，而且我又很爱打球。\n",
            "前端处理后的文本(每句): 尊师重道,那时候他很希望我可以考上音乐系,然后读大学.这样对,让我大概考了两次吧,可能我不是读书的料,而且我又很爱打球.\n",
            " 24% 360/1500 [00:04<00:10, 104.45it/s]T2S Decoding EOS [112 -> 473]\n",
            " 24% 360/1500 [00:04<00:13, 86.30it/s] \n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "2.149\t8.829\t4.195\t11.780\n",
            "实际输入的参考文本: 尊师重道，那时候他很希望我可以考上音乐系，然后读大学。这样对，让我大概考了两次吧，可能我不是读书的料，而且我又很爱打球。\n",
            "实际输入的目标文本: 大家好，我是周杰伦。雨下整夜，我的爱溢出就像雨水。还不错吧。\n",
            "实际输入的目标文本(切句后): 大家好，我是周杰伦。雨下整夜，我的爱溢出就像雨水。还不错吧。\n",
            "实际输入的目标文本(每句): 大家好，我是周杰伦。雨下整夜，我的爱溢出就像雨水。还不错吧。\n",
            "前端处理后的文本(每句): 大家好,我是周杰伦.雨下整夜,我的爱溢出就像雨水.还不错吧.\n",
            " 16% 246/1500 [00:02<00:11, 106.12it/s]T2S Decoding EOS [112 -> 360]\n",
            " 16% 247/1500 [00:02<00:11, 104.72it/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.111\t0.982\t2.361\t7.537\n",
            "实际输入的参考文本: 尊师重道，那时候他很希望我可以考上音乐系，然后读大学。这样对，让我大概考了两次吧，可能我不是读书的料，而且我又很爱打球。\n",
            "实际输入的目标文本: 大家好，我是周杰伦。雨下整夜，我的爱溢出就像雨水。还不错吧。\n",
            "实际输入的目标文本(切句后): 大家好，我是周杰伦。雨下整夜，我的爱溢出就像雨水。还不错吧。\n",
            "实际输入的目标文本(每句): 大家好，我是周杰伦。雨下整夜，我的爱溢出就像雨水。还不错吧。\n",
            "前端处理后的文本(每句): 大家好,我是周杰伦.雨下整夜,我的爱溢出就像雨水.还不错吧.\n",
            " 16% 243/1500 [00:02<00:12, 103.39it/s]T2S Decoding EOS [112 -> 356]\n",
            " 16% 243/1500 [00:02<00:12, 101.47it/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.083\t0.960\t2.397\t7.414\n",
            "实际输入的参考文本: 搭公车，大家有这样的经验吧，就是人很多了。时后被挤到最后，然后被公车门夹到。\n",
            "实际输入的目标文本: 大家好，我是周杰伦。雨下整夜，我的爱溢出就像雨水。还不错吧。\n",
            "实际输入的目标文本(切句后): 大家好，我是周杰伦。雨下整夜，我的爱溢出就像雨水。还不错吧。\n",
            "实际输入的目标文本(每句): 大家好，我是周杰伦。雨下整夜，我的爱溢出就像雨水。还不错吧。\n",
            "前端处理后的文本(每句): 大家好,我是周杰伦.雨下整夜,我的爱溢出就像雨水.还不错吧.\n",
            "  7% 112/1500 [00:01<00:14, 95.42it/s]T2S Decoding EOS [170 -> 285]\n",
            "  8% 114/1500 [00:01<00:15, 86.69it/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.217\t1.746\t1.318\t3.917\n",
            "实际输入的参考文本: 搭公车，大家有这样的经验吧，就是人很多了。时后被挤到最后，然后被公车门夹到。\n",
            "实际输入的目标文本: 大家好，我是周杰伦。雨下整夜，我的爱溢出就像雨水。还不错吧。\n",
            "实际输入的目标文本(切句后): 大家好，我是周杰伦。雨下整夜，我的爱溢出就像雨水。还不错吧。\n",
            "实际输入的目标文本(每句): 大家好，我是周杰伦。雨下整夜，我的爱溢出就像雨水。还不错吧。\n",
            "前端处理后的文本(每句): 大家好,我是周杰伦.雨下整夜,我的爱溢出就像雨水.还不错吧.\n",
            "  8% 121/1500 [00:01<00:13, 101.93it/s]T2S Decoding EOS [170 -> 296]\n",
            "  8% 125/1500 [00:01<00:13, 102.00it/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.200\t1.040\t1.228\t4.131\n",
            "实际输入的参考文本: 搭公车，大家有这样的经验吧，就是人很多了。时后被挤到最后，然后被公车门夹到。\n",
            "实际输入的目标文本: 我是周杰伦。雨下整夜，我的爱溢出就像雨水。还不错吧。\n",
            "实际输入的目标文本(切句后): 我是周杰伦。雨下整夜，我的爱溢出就像雨水。还不错吧。\n",
            "实际输入的目标文本(每句): 我是周杰伦。雨下整夜，我的爱溢出就像雨水。还不错吧。\n",
            "前端处理后的文本(每句): 我是周杰伦.雨下整夜,我的爱溢出就像雨水.还不错吧.\n",
            "  8% 122/1500 [00:01<00:13, 104.97it/s]T2S Decoding EOS [170 -> 299]\n",
            "  9% 128/1500 [00:01<00:13, 101.89it/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.122\t0.738\t1.259\t6.521\n",
            "实际输入的参考文本: 搭公车，大家有这样的经验吧，就是人很多了。时后被挤到最后，然后被公车门夹到。\n",
            "实际输入的目标文本: 我是周杰伦。雨下整夜，我的爱溢出就像雨水。还不错吧。\n",
            "实际输入的目标文本(切句后): 我是周杰伦。雨下整夜，我的爱溢出就像雨水。还不错吧。\n",
            "实际输入的目标文本(每句): 我是周杰伦。雨下整夜，我的爱溢出就像雨水。还不错吧。\n",
            "前端处理后的文本(每句): 我是周杰伦.雨下整夜,我的爱溢出就像雨水.还不错吧.\n",
            "  8% 121/1500 [00:01<00:13, 105.12it/s]T2S Decoding EOS [170 -> 294]\n",
            "  8% 123/1500 [00:01<00:13, 101.86it/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.133\t0.659\t1.210\t4.126\n"
          ]
        }
      ],
      "source": [
        "# @title 一键开启GPT-SoVITS-v3\n",
        "\n",
        "!pip install -q condacolab\n",
        "# Setting up condacolab and installing packages\n",
        "import condacolab\n",
        "condacolab.install_from_url(\"https://repo.anaconda.com/miniconda/Miniconda3-py39_23.11.0-2-Linux-x86_64.sh\")\n",
        "!git clone https://huggingface.co/kevinwang676/GPT-SoVITS-v3.git\n",
        "!conda install -y -q -c pytorch -c nvidia cudatoolkit\n",
        "%cd GPT-SoVITS-v3\n",
        "!conda install -y -q -c conda-forge gcc gxx ffmpeg cmake -c pytorch -c nvidia\n",
        "!/usr/local/bin/pip install -r requirements.txt\n",
        "!sudo apt install ffmpeg\n",
        "!sudo apt install libsox-dev\n",
        "!pip install LangSegment\n",
        "!pip install numpy==1.23.4\n",
        "import nltk\n",
        "nltk.download(\"all\")\n",
        "!mv tools/damo_asr/speech_fsmn_vad_zh-cn-16k-common-pytorch tools/asr/models/\n",
        "!mv tools/damo_asr/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch tools/asr/models/\n",
        "!mv tools/damo_asr/punc_ct-transformer_zh-cn-common-vocab272727-pytorch tools/asr/models/\n",
        "!/usr/local/bin/pip install ipykernel\n",
        "!sed -i '10s/False/True/' /content/GPT-SoVITS-v3/config.py\n",
        "%cd /content/GPT-SoVITS-v3/\n",
        "!/usr/local/bin/python webui.py zh_CN"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LENDan0wB16N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}